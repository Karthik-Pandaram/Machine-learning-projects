# -*- coding: utf-8 -*-
"""Ships Classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SfkL0oBe5gNzvE2B0D6hoIHEGwIbMypM
"""

# Ships classifier using CNN from scratch, with Tensorflow and sklearn

import tensorflow as tf
import numpy as np
import pandas as pd

# Read the Shipsnet json dataset in pandas framework for further processing
df = pd.read_json("/content/drive/MyDrive/Colab Notebooks/shipsnet.json")

# Normalize and reshape the image data
# The pixel values are stored in a column in the data frame titled “data.”
# As is, these pixel values aren’t ready to be processed by a CNN.
# Instead, the new data is converted to a NumPy array and divided by 255 to normalize the values. 
# All 19,200 values should now be some value between 0 and 1. 
# Next the data is reshaped to 80 x 80 x 3 matrix so that it’s formatted as a picture.
df["normalized_data"] = df["data"].apply(lambda x: (np.array(x) / 255).reshape(80, 80, 3))

# Define X and Y
X = df["normalized_data"]
Y = df["labels"]

#Spliting the data into training data and Testing data using Sklearn
# Split the data into training and testing sets. Use a 75/25 split
from sklearn.model_selection import train_test_split
(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.25, random_state=42)

# As Pandas Series aren’t accepted in TensorFlow, so the training and testing data are converted into arrays.
# Transform the training and testing data into arrays
X_train = np.array([x for x in X_train])
X_test = np.array([x for x in X_test])
Y_train = np.array([y for y in Y_train])
Y_test = np.array([y for y in Y_test])

from tensorflow.keras import datasets, layers, models
from tensorflow.keras.layers import Activation

# To the start the model with sequential ANN
model = models.Sequential()

# Adds the first convolusion layer and followed by max pooling

model.add(layers.Conv2D(32, kernel_size=(3,3), activation= 'relu', input_shape = (80, 80, 3)))
# Max pooling layer

model.add(layers.MaxPool2D((2,2)))

#Additional Hidden Layers
model.add(layers.Conv2D(64,kernel_size=(3,3), activation= 'relu'))
model.add(layers.MaxPool2D(pool_size=(2,2)))
model.add(layers.Conv2D(64,kernel_size=(3,3), activation= 'relu'))

# Flattens the input into a 1D tensor
model.add(layers.Flatten())
# Makes the input more readable for classification
model.add(layers.Dense(64, activation='relu'))
# Classifies - ensure the input in the number of classes, indexed
# at 0
model.add(layers.Dense(1))
# Final activation function
model.add(Activation('sigmoid'))

model.summary()

# Compile the model
# Use binary_crossentropy because there are only 2 classes present

model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

# The above line simply compiles the model. 
# If there were issues with input/output dimensionality while adding layers, 
# the program will let you know at this step.

# Training the model 
gen_model = model.fit(x = X_train, y= Y_train, epochs =20 , validation_data= (X_test, Y_test))

# Evaluate the model
from sklearn.metrics import classification_report, confusion_matrix
predictions = model.predict(X_test)
print(classification_report(Y_test, predictions.round()))
print(confusion_matrix(Y_test, predictions.round()))

# Save the model for later use
model.save("ShipCNN.h5")

# Load a model
new_model = tf.keras.models.load_model("ShipCNN.h5")

