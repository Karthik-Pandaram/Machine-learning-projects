{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ships Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTmx5Jrj_vWd"
      },
      "source": [
        "# Ships classifier using CNN from scratch, with Tensorflow and sklearn\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLZuVYUCAQzz"
      },
      "source": [
        "# Read the Shipsnet json dataset in pandas framework for further processing\n",
        "df = pd.read_json(\"/content/drive/MyDrive/Colab Notebooks/shipsnet.json\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaCw0TePAd-0"
      },
      "source": [
        "# Normalize and reshape the image data\n",
        "# The pixel values are stored in a column in the data frame titled “data.”\n",
        "# As is, these pixel values aren’t ready to be processed by a CNN.\n",
        "# Instead, the new data is converted to a NumPy array and divided by 255 to normalize the values. \n",
        "# All 19,200 values should now be some value between 0 and 1. \n",
        "# Next the data is reshaped to 80 x 80 x 3 matrix so that it’s formatted as a picture.\n",
        "df[\"normalized_data\"] = df[\"data\"].apply(lambda x: (np.array(x) / 255).reshape(80, 80, 3))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgjIS3rbAn-U"
      },
      "source": [
        "# Define X and Y\n",
        "X = df[\"normalized_data\"]\n",
        "Y = df[\"labels\"]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goJcu4rcA_v6"
      },
      "source": [
        "#Spliting the data into training data and Testing data using Sklearn\n",
        "# Split the data into training and testing sets. Use a 75/25 split\n",
        "from sklearn.model_selection import train_test_split\n",
        "(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.25, random_state=42)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbxtRs5nB_S6"
      },
      "source": [
        "# As Pandas Series aren’t accepted in TensorFlow, so the training and testing data are converted into arrays.\n",
        "# Transform the training and testing data into arrays\n",
        "X_train = np.array([x for x in X_train])\n",
        "X_test = np.array([x for x in X_test])\n",
        "Y_train = np.array([y for y in Y_train])\n",
        "Y_test = np.array([y for y in Y_test])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVEckSekCDmV"
      },
      "source": [
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.layers import Activation\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCrMQcA-Cs3m"
      },
      "source": [
        "# To the start the model with sequential ANN\n",
        "model = models.Sequential()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaHj5_15C1sN"
      },
      "source": [
        "# Adds the first convolusion layer and followed by max pooling\n",
        "\n",
        "model.add(layers.Conv2D(32, kernel_size=(3,3), activation= 'relu', input_shape = (80, 80, 3)))\n",
        "# Max pooling layer\n",
        "\n",
        "model.add(layers.MaxPool2D((2,2)))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y60nnIBuDjgU"
      },
      "source": [
        "#Additional Hidden Layers\n",
        "model.add(layers.Conv2D(64,kernel_size=(3,3), activation= 'relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "model.add(layers.Conv2D(64,kernel_size=(3,3), activation= 'relu'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB47oGFfEa8Y"
      },
      "source": [
        "# Flattens the input into a 1D tensor\n",
        "model.add(layers.Flatten())\n",
        "# Makes the input more readable for classification\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# Classifies - ensure the input in the number of classes, indexed\n",
        "# at 0\n",
        "model.add(layers.Dense(1))\n",
        "# Final activation function\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhhZyX6fEn6o",
        "outputId": "a96606ae-5ed4-4a77-a7b4-52b0570a967b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 78, 78, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 39, 39, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 37, 37, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 18, 18, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                1048640   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 1,105,025\n",
            "Trainable params: 1,105,025\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAr09F-HEqSU"
      },
      "source": [
        "# Compile the model\n",
        "# Use binary_crossentropy because there are only 2 classes present\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "# The above line simply compiles the model. \n",
        "# If there were issues with input/output dimensionality while adding layers, \n",
        "# the program will let you know at this step."
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZzrP_CbE_8B",
        "outputId": "e6dbd90e-f13b-4342-d500-4b829c522198"
      },
      "source": [
        "# Training the model \n",
        "gen_model = model.fit(x = X_train, y= Y_train, epochs =20 , validation_data= (X_test, Y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "94/94 [==============================] - 34s 16ms/step - loss: 0.4876 - accuracy: 0.8172 - val_loss: 0.1990 - val_accuracy: 0.9250\n",
            "Epoch 2/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.1667 - accuracy: 0.9351 - val_loss: 0.0912 - val_accuracy: 0.9680\n",
            "Epoch 3/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0768 - accuracy: 0.9696 - val_loss: 0.0575 - val_accuracy: 0.9830\n",
            "Epoch 4/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0549 - accuracy: 0.9816 - val_loss: 0.0478 - val_accuracy: 0.9870\n",
            "Epoch 5/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0412 - accuracy: 0.9873 - val_loss: 0.0626 - val_accuracy: 0.9800\n",
            "Epoch 6/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0268 - accuracy: 0.9902 - val_loss: 0.0583 - val_accuracy: 0.9870\n",
            "Epoch 7/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0190 - accuracy: 0.9952 - val_loss: 0.0346 - val_accuracy: 0.9900\n",
            "Epoch 8/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0282 - accuracy: 0.9892 - val_loss: 0.0622 - val_accuracy: 0.9760\n",
            "Epoch 9/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0162 - accuracy: 0.9935 - val_loss: 0.0471 - val_accuracy: 0.9880\n",
            "Epoch 10/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.0827 - val_accuracy: 0.9770\n",
            "Epoch 11/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0800 - val_accuracy: 0.9810\n",
            "Epoch 12/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0109 - accuracy: 0.9959 - val_loss: 0.0618 - val_accuracy: 0.9870\n",
            "Epoch 13/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0558 - val_accuracy: 0.9870\n",
            "Epoch 14/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.1265 - val_accuracy: 0.9840\n",
            "Epoch 15/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.3404 - val_accuracy: 0.9610\n",
            "Epoch 16/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.0777 - val_accuracy: 0.9860\n",
            "Epoch 17/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.1019 - val_accuracy: 0.9860\n",
            "Epoch 18/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.1892 - val_accuracy: 0.9800\n",
            "Epoch 19/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.1032 - val_accuracy: 0.9780\n",
            "Epoch 20/20\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.1244 - val_accuracy: 0.9870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4VI-5tgFlO3",
        "outputId": "42107e42-431b-44c2-8ea5-9a7573b51f3d"
      },
      "source": [
        "# Evaluate the model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "predictions = model.predict(X_test)\n",
        "print(classification_report(Y_test, predictions.round()))\n",
        "print(confusion_matrix(Y_test, predictions.round()))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       733\n",
            "           1       0.98      0.97      0.98       267\n",
            "\n",
            "    accuracy                           0.99      1000\n",
            "   macro avg       0.99      0.98      0.98      1000\n",
            "weighted avg       0.99      0.99      0.99      1000\n",
            "\n",
            "[[729   4]\n",
            " [  9 258]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cABRXaIkHJNg"
      },
      "source": [
        "# Save the model for later use\n",
        "model.save(\"ShipCNN.h5\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmRCFwbQHNxl"
      },
      "source": [
        "# Load a model\n",
        "new_model = tf.keras.models.load_model(\"ShipCNN.h5\")\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG5f--abHTtE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}