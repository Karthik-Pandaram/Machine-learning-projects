{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Signals lstm_seq2seq",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthik-Pandaram/Machine-learning-projects/blob/main/Signals_lstm_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0G4eeSuCfUA"
      },
      "source": [
        "# Character-level recurrent sequence-to-sequence model\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2017/09/29<br>\n",
        "**Last modified:** 2020/04/26<br>\n",
        "**Description:** Character-level recurrent sequence-to-sequence model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUT0YPB_CfUF"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This example demonstrates how to implement a basic character-level\n",
        "recurrent sequence-to-sequence model. We apply it to translating\n",
        "short English sentences into short French sentences,\n",
        "character-by-character. Note that it is fairly unusual to\n",
        "do character-level machine translation, as word-level\n",
        "models are more common in this domain.\n",
        "\n",
        "**Summary of the algorithm**\n",
        "\n",
        "- We start with input sequences from a domain (e.g. English sentences)\n",
        "    and corresponding target sequences from another domain\n",
        "    (e.g. French sentences).\n",
        "- An encoder LSTM turns input sequences to 2 state vectors\n",
        "    (we keep the last LSTM state and discard the outputs).\n",
        "- A decoder LSTM is trained to turn the target sequences into\n",
        "    the same sequence but offset by one timestep in the future,\n",
        "    a training process called \"teacher forcing\" in this context.\n",
        "    It uses as initial state the state vectors from the encoder.\n",
        "    Effectively, the decoder learns to generate `targets[t+1...]`\n",
        "    given `targets[...t]`, conditioned on the input sequence.\n",
        "- In inference mode, when we want to decode unknown input sequences, we:\n",
        "    - Encode the input sequence into state vectors\n",
        "    - Start with a target sequence of size 1\n",
        "        (just the start-of-sequence character)\n",
        "    - Feed the state vectors and 1-char target sequence\n",
        "        to the decoder to produce predictions for the next character\n",
        "    - Sample the next character using these predictions\n",
        "        (we simply use argmax).\n",
        "    - Append the sampled character to the target sequence\n",
        "    - Repeat until we generate the end-of-sequence character or we\n",
        "        hit the character limit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9uzSJhvCfUH"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9roA2p4gCfUI"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87_iLTniCfUJ"
      },
      "source": [
        "## Download the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyS9edQoCfUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60eefae8-0727-4379-f25d-c58cf1b53fb7"
      },
      "source": [
        "!!curl -O http://www.manythings.org/anki/fra-eng.zip\n",
        "!!unzip fra-eng.zip\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Archive:  fra-eng.zip',\n",
              " '  inflating: _about.txt              ',\n",
              " '  inflating: fra.txt                 ']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isc5hQVeCfUL"
      },
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06jsjJBQCfUM"
      },
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "# Path to the data txt file on disk.\n",
        "data_path = \"fra.txt\"\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwuY5eT4CfUN"
      },
      "source": [
        "## Prepare the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_k22rQzlw9k"
      },
      "source": [
        "#Change input text to sequences \n",
        "X = list()\n",
        "Y = list()\n",
        "X = [x for x in range(0, 1000, 1)]\n",
        "Y = [y for y in range(1000, 0, -1)]\n",
        "\n",
        "X = np.array(X).reshape(20, 50)\n",
        "Y = np.array(Y).reshape(20, 50)\n",
        "inwave = [ ]\n",
        "tarwave = [ ]\n",
        "for wav in X:\n",
        " inwave.append(np.array2string(wav,max_line_width=1000, precision=2, separator=',',\n",
        "                      suppress_small=True,))\n",
        "for wav in Y:\n",
        " tarwave.append(np.array2string(wav,max_line_width=1000, precision=2, separator=',',\n",
        "                      suppress_small=True))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "bcKNVZpiDvtW",
        "outputId": "f8a0fd5d-57ea-4621-907c-254f6a1c5e94"
      },
      "source": [
        "tarwave[10]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[500,499,498,497,496,495,494,493,492,491,490,489,488,487,486,485,484,483,482,481,480,479,478,477,476,475,474,473,472,471,470,469,468,467,466,465,464,463,462,461,460,459,458,457,456,455,454,453,452,451]'"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYJDfCmgCfUO"
      },
      "source": [
        "# Vectorize the data.\n",
        "# inwave = []\n",
        "# target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "# with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "#     lines = f.read().split(\"\\n\")\n",
        "for line in inwave:\n",
        "    # input_text, target_text, _ = line.split(\"\\t\")\n",
        "    # # We use \"tab\" as the \"start sequence\" character\n",
        "    # # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    # target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    # input_texts.append(input_text)\n",
        "    # target_texts.append(target_text)\n",
        "    for char in line:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "for line in tarwave:            \n",
        "    for char in line:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8D8bDhhFhrw",
        "outputId": "22178820-ef6d-4673-dec4-8eb652a7efe1"
      },
      "source": [
        "input_characters"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ', ',', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '[', ']'}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69psgZ0ZF_tx",
        "outputId": "49f32206-2ee0-4e31-dd54-be419940f024"
      },
      "source": [
        "len(inwave)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J32QgnqUF0bO"
      },
      "source": [
        "Character encodind done ok!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZizlYvk5lo5-",
        "outputId": "bccbed0a-029d-446c-d0f6-0b1cb93a7ab7"
      },
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in inwave])\n",
        "max_decoder_seq_length = max([len(txt) for txt in tarwave])\n",
        "\n",
        "print(\"Number of samples:\", len(inwave))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(inwave), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(inwave), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(inwave), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(inwave, tarwave)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 20\n",
            "Number of unique input tokens: 14\n",
            "Number of unique output tokens: 14\n",
            "Max sequence length for inputs: 201\n",
            "Max sequence length for outputs: 251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb1L9XWvDrDn"
      },
      "source": [
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7oJm4XiEwqL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3abc5237-c392-43de-e04b-b2979507e3cf"
      },
      "source": [
        "encoder_input_data"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 1., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 1., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 1., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 1., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 1., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 1., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 1., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 1.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 1., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 1., 0., 0.],\n",
              "        [0., 0., 0., ..., 1., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 1.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 1., 0.],\n",
              "        [0., 0., 0., ..., 1., 0., 0.],\n",
              "        [0., 0., 1., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 1., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 1.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 1., 0.],\n",
              "        [0., 0., 0., ..., 1., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 1., 0., 0.],\n",
              "        [0., 0., 0., ..., 1., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 1.]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyOeF4XfDxAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a21e8bc-2679-470f-f73a-a31b890fd9e7"
      },
      "source": [
        "inwave"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49]',\n",
              " '[50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99]',\n",
              " '[100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149]',\n",
              " '[150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199]',\n",
              " '[200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249]',\n",
              " '[250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299]',\n",
              " '[300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349]',\n",
              " '[350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399]',\n",
              " '[400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449]',\n",
              " '[450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499]',\n",
              " '[500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549]',\n",
              " '[550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599]',\n",
              " '[600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649]',\n",
              " '[650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699]',\n",
              " '[700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749]',\n",
              " '[750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799]',\n",
              " '[800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849]',\n",
              " '[850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899]',\n",
              " '[900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949]',\n",
              " '[950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999]']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6dzuDeXCfUQ"
      },
      "source": [
        "## Build the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1URGpVWACfUQ"
      },
      "source": [
        "# Define an input sequence and process it.\n",
        "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
        "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUgOGMHbCfUR"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mm_DIcDCfUR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c8454b7a-168a-487a-d35e-214305e40ef8"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "history = model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=1000,\n",
        "    validation_split=0.2,\n",
        ")\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# Save model\n",
        "model.save(\"s2s\")\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 2.6249 - accuracy: 0.2263 - val_loss: 2.4087 - val_accuracy: 0.4462\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 2.4620 - accuracy: 0.3802 - val_loss: 2.1408 - val_accuracy: 0.3635\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 2.2053 - accuracy: 0.2918 - val_loss: 2.3424 - val_accuracy: 0.4173\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 2.3641 - accuracy: 0.3541 - val_loss: 2.5192 - val_accuracy: 0.3416\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 2.5530 - accuracy: 0.2761 - val_loss: 2.2367 - val_accuracy: 0.4472\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 2.3122 - accuracy: 0.3835 - val_loss: 2.1037 - val_accuracy: 0.4512\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 2.2160 - accuracy: 0.3884 - val_loss: 1.9339 - val_accuracy: 0.4343\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 2.1026 - accuracy: 0.3830 - val_loss: 1.9953 - val_accuracy: 0.3735\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 2.0856 - accuracy: 0.3187 - val_loss: 2.0604 - val_accuracy: 0.4452\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 2.1556 - accuracy: 0.3817 - val_loss: 1.9354 - val_accuracy: 0.4482\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 2.0650 - accuracy: 0.3800 - val_loss: 1.8710 - val_accuracy: 0.4482\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 2.0124 - accuracy: 0.3815 - val_loss: 1.8511 - val_accuracy: 0.4512\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 1.9744 - accuracy: 0.3850 - val_loss: 1.8552 - val_accuracy: 0.4472\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 1.9372 - accuracy: 0.3775 - val_loss: 2.0032 - val_accuracy: 0.3725\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 2.0647 - accuracy: 0.3005 - val_loss: 2.0693 - val_accuracy: 0.4104\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 2.0886 - accuracy: 0.3513 - val_loss: 1.9463 - val_accuracy: 0.4432\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 2.0248 - accuracy: 0.3762 - val_loss: 1.9005 - val_accuracy: 0.4422\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 1.9780 - accuracy: 0.3725 - val_loss: 1.8835 - val_accuracy: 0.4432\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 1.9567 - accuracy: 0.3713 - val_loss: 1.8709 - val_accuracy: 0.4422\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 1.9388 - accuracy: 0.3733 - val_loss: 1.8579 - val_accuracy: 0.4422\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 1.9230 - accuracy: 0.3723 - val_loss: 1.8493 - val_accuracy: 0.4452\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 1.9087 - accuracy: 0.3757 - val_loss: 1.8403 - val_accuracy: 0.4462\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 1.8950 - accuracy: 0.3762 - val_loss: 1.8372 - val_accuracy: 0.4452\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 1.8812 - accuracy: 0.3765 - val_loss: 1.8373 - val_accuracy: 0.4492\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.8682 - accuracy: 0.3790 - val_loss: 1.8310 - val_accuracy: 0.4452\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 1.8864 - accuracy: 0.3847 - val_loss: 2.4420 - val_accuracy: 0.3506\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 2.3001 - accuracy: 0.2986 - val_loss: 1.8324 - val_accuracy: 0.4542\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 1.9456 - accuracy: 0.3927 - val_loss: 1.8052 - val_accuracy: 0.4492\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 1.9102 - accuracy: 0.3847 - val_loss: 1.7798 - val_accuracy: 0.4492\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.8806 - accuracy: 0.3875 - val_loss: 1.7641 - val_accuracy: 0.4432\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.8647 - accuracy: 0.3782 - val_loss: 1.7583 - val_accuracy: 0.4542\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 1.8536 - accuracy: 0.3884 - val_loss: 1.7551 - val_accuracy: 0.4452\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.8497 - accuracy: 0.3745 - val_loss: 1.7846 - val_accuracy: 0.4532\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.8820 - accuracy: 0.3952 - val_loss: 1.7513 - val_accuracy: 0.4462\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.8333 - accuracy: 0.3785 - val_loss: 1.7448 - val_accuracy: 0.4562\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.8168 - accuracy: 0.3892 - val_loss: 1.7275 - val_accuracy: 0.4492\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.8025 - accuracy: 0.3850 - val_loss: 1.8543 - val_accuracy: 0.4492\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.8685 - accuracy: 0.3825 - val_loss: 1.7507 - val_accuracy: 0.4422\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.8559 - accuracy: 0.3860 - val_loss: 1.7520 - val_accuracy: 0.4502\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.8156 - accuracy: 0.3855 - val_loss: 1.7227 - val_accuracy: 0.4512\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 1.8127 - accuracy: 0.3899 - val_loss: 1.7842 - val_accuracy: 0.4502\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.8177 - accuracy: 0.3917 - val_loss: 1.7230 - val_accuracy: 0.4522\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.7984 - accuracy: 0.3909 - val_loss: 1.7147 - val_accuracy: 0.4512\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.7819 - accuracy: 0.3867 - val_loss: 1.7829 - val_accuracy: 0.4532\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.8157 - accuracy: 0.4041 - val_loss: 1.7453 - val_accuracy: 0.4572\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.7693 - accuracy: 0.3964 - val_loss: 1.7074 - val_accuracy: 0.4631\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 1.7542 - accuracy: 0.3984 - val_loss: 1.8040 - val_accuracy: 0.4442\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.7995 - accuracy: 0.3892 - val_loss: 1.7281 - val_accuracy: 0.4532\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.8100 - accuracy: 0.4148 - val_loss: 1.7020 - val_accuracy: 0.4512\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.7619 - accuracy: 0.4116 - val_loss: 1.7120 - val_accuracy: 0.4562\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.7676 - accuracy: 0.4034 - val_loss: 1.7382 - val_accuracy: 0.4323\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.8245 - accuracy: 0.3897 - val_loss: 1.7925 - val_accuracy: 0.4442\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.8187 - accuracy: 0.4029 - val_loss: 1.7387 - val_accuracy: 0.4532\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.7740 - accuracy: 0.4069 - val_loss: 1.6951 - val_accuracy: 0.4582\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.7294 - accuracy: 0.4044 - val_loss: 1.6839 - val_accuracy: 0.4622\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.7036 - accuracy: 0.4109 - val_loss: 1.7036 - val_accuracy: 0.4512\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.7291 - accuracy: 0.4084 - val_loss: 1.8244 - val_accuracy: 0.4213\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.8583 - accuracy: 0.3879 - val_loss: 1.7455 - val_accuracy: 0.4502\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.7658 - accuracy: 0.4198 - val_loss: 1.6819 - val_accuracy: 0.4562\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.7314 - accuracy: 0.4114 - val_loss: 1.7572 - val_accuracy: 0.4542\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.7509 - accuracy: 0.4151 - val_loss: 1.6804 - val_accuracy: 0.4701\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.7202 - accuracy: 0.4198 - val_loss: 1.6478 - val_accuracy: 0.4631\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.7151 - accuracy: 0.4186 - val_loss: 1.7392 - val_accuracy: 0.4661\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.7203 - accuracy: 0.4280 - val_loss: 1.6766 - val_accuracy: 0.4602\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.6855 - accuracy: 0.4236 - val_loss: 1.6700 - val_accuracy: 0.4631\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.6878 - accuracy: 0.4236 - val_loss: 1.7202 - val_accuracy: 0.4592\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.7073 - accuracy: 0.4338 - val_loss: 1.6960 - val_accuracy: 0.4492\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.6990 - accuracy: 0.4153 - val_loss: 1.6987 - val_accuracy: 0.4492\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.6812 - accuracy: 0.4268 - val_loss: 1.6559 - val_accuracy: 0.4592\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.7167 - accuracy: 0.4340 - val_loss: 1.7125 - val_accuracy: 0.4512\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.7225 - accuracy: 0.4094 - val_loss: 1.6547 - val_accuracy: 0.4711\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.6850 - accuracy: 0.4345 - val_loss: 1.6229 - val_accuracy: 0.4671\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.6403 - accuracy: 0.4275 - val_loss: 1.6326 - val_accuracy: 0.4602\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.6165 - accuracy: 0.4353 - val_loss: 1.6162 - val_accuracy: 0.4622\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.6292 - accuracy: 0.4293 - val_loss: 1.8270 - val_accuracy: 0.4233\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.7890 - accuracy: 0.3947 - val_loss: 1.8646 - val_accuracy: 0.4392\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.8411 - accuracy: 0.3977 - val_loss: 1.7494 - val_accuracy: 0.4492\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.7585 - accuracy: 0.4258 - val_loss: 1.7132 - val_accuracy: 0.4781\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.7145 - accuracy: 0.4477 - val_loss: 1.6863 - val_accuracy: 0.4681\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.6846 - accuracy: 0.4345 - val_loss: 1.6713 - val_accuracy: 0.4671\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.6610 - accuracy: 0.4325 - val_loss: 1.6629 - val_accuracy: 0.4562\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.6528 - accuracy: 0.4283 - val_loss: 1.6944 - val_accuracy: 0.4582\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 1.6764 - accuracy: 0.4470 - val_loss: 1.6336 - val_accuracy: 0.4641\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.6386 - accuracy: 0.4305 - val_loss: 1.6188 - val_accuracy: 0.4631\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.6113 - accuracy: 0.4380 - val_loss: 1.6453 - val_accuracy: 0.4532\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.6152 - accuracy: 0.4397 - val_loss: 1.6236 - val_accuracy: 0.4522\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.6526 - accuracy: 0.4465 - val_loss: 1.6417 - val_accuracy: 0.4661\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.6182 - accuracy: 0.4547 - val_loss: 1.5956 - val_accuracy: 0.4572\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.5801 - accuracy: 0.4447 - val_loss: 1.6271 - val_accuracy: 0.4701\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.5969 - accuracy: 0.4465 - val_loss: 1.6643 - val_accuracy: 0.4522\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.6635 - accuracy: 0.4303 - val_loss: 1.6889 - val_accuracy: 0.4631\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.6562 - accuracy: 0.4512 - val_loss: 1.6476 - val_accuracy: 0.4751\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.6005 - accuracy: 0.4502 - val_loss: 1.6353 - val_accuracy: 0.4771\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.6081 - accuracy: 0.4534 - val_loss: 1.6062 - val_accuracy: 0.4761\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.5752 - accuracy: 0.4519 - val_loss: 1.6044 - val_accuracy: 0.4771\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.5564 - accuracy: 0.4617 - val_loss: 1.6290 - val_accuracy: 0.4602\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.5854 - accuracy: 0.4542 - val_loss: 1.6062 - val_accuracy: 0.4661\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.6060 - accuracy: 0.4607 - val_loss: 1.5969 - val_accuracy: 0.4791\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.5648 - accuracy: 0.4766 - val_loss: 1.5965 - val_accuracy: 0.4602\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.5460 - accuracy: 0.4619 - val_loss: 1.5979 - val_accuracy: 0.4651\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.5614 - accuracy: 0.4622 - val_loss: 1.6223 - val_accuracy: 0.4681\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 1.6105 - accuracy: 0.4619 - val_loss: 1.6114 - val_accuracy: 0.4582\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.5920 - accuracy: 0.4554 - val_loss: 1.5925 - val_accuracy: 0.4711\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.5402 - accuracy: 0.4714 - val_loss: 1.5872 - val_accuracy: 0.4622\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.5379 - accuracy: 0.4629 - val_loss: 1.5931 - val_accuracy: 0.4641\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.5541 - accuracy: 0.4634 - val_loss: 1.6355 - val_accuracy: 0.4681\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.5426 - accuracy: 0.4806 - val_loss: 1.5629 - val_accuracy: 0.4821\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.5298 - accuracy: 0.4617 - val_loss: 1.6435 - val_accuracy: 0.4592\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.5663 - accuracy: 0.4691 - val_loss: 1.5886 - val_accuracy: 0.4920\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.5591 - accuracy: 0.4694 - val_loss: 1.5902 - val_accuracy: 0.4781\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.5351 - accuracy: 0.4763 - val_loss: 1.5459 - val_accuracy: 0.4970\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.5211 - accuracy: 0.4766 - val_loss: 1.5897 - val_accuracy: 0.4831\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.5200 - accuracy: 0.4751 - val_loss: 1.5699 - val_accuracy: 0.4811\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.4888 - accuracy: 0.4846 - val_loss: 1.5749 - val_accuracy: 0.4721\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 1.4937 - accuracy: 0.4773 - val_loss: 1.5345 - val_accuracy: 0.4811\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.5349 - accuracy: 0.4619 - val_loss: 1.5778 - val_accuracy: 0.4691\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.5456 - accuracy: 0.4656 - val_loss: 1.5539 - val_accuracy: 0.4920\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.5237 - accuracy: 0.4778 - val_loss: 1.5560 - val_accuracy: 0.4890\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.4870 - accuracy: 0.4848 - val_loss: 1.5599 - val_accuracy: 0.4801\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.4959 - accuracy: 0.4744 - val_loss: 1.5593 - val_accuracy: 0.4731\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.5352 - accuracy: 0.4761 - val_loss: 1.5336 - val_accuracy: 0.4900\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.4927 - accuracy: 0.4773 - val_loss: 1.5402 - val_accuracy: 0.4801\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.4913 - accuracy: 0.4873 - val_loss: 1.5812 - val_accuracy: 0.4671\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.4771 - accuracy: 0.4843 - val_loss: 1.5416 - val_accuracy: 0.4851\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.4607 - accuracy: 0.4816 - val_loss: 1.5414 - val_accuracy: 0.4950\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 1.5381 - accuracy: 0.4821 - val_loss: 1.6297 - val_accuracy: 0.4452\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.5609 - accuracy: 0.4746 - val_loss: 1.5553 - val_accuracy: 0.5050\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.5000 - accuracy: 0.5062 - val_loss: 1.5430 - val_accuracy: 0.4900\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.4661 - accuracy: 0.5002 - val_loss: 1.5529 - val_accuracy: 0.5030\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.4782 - accuracy: 0.4988 - val_loss: 1.5369 - val_accuracy: 0.4920\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.4521 - accuracy: 0.5015 - val_loss: 1.5176 - val_accuracy: 0.5040\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.4279 - accuracy: 0.5010 - val_loss: 1.5325 - val_accuracy: 0.4960\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.4447 - accuracy: 0.4953 - val_loss: 1.5192 - val_accuracy: 0.4861\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.4349 - accuracy: 0.5012 - val_loss: 1.5393 - val_accuracy: 0.5090\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 1.4366 - accuracy: 0.4975 - val_loss: 1.5900 - val_accuracy: 0.4731\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.5181 - accuracy: 0.4781 - val_loss: 1.4897 - val_accuracy: 0.5100\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.4560 - accuracy: 0.5154 - val_loss: 1.5162 - val_accuracy: 0.5070\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.4196 - accuracy: 0.5147 - val_loss: 1.5012 - val_accuracy: 0.4851\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.4334 - accuracy: 0.5057 - val_loss: 1.5380 - val_accuracy: 0.4980\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.4181 - accuracy: 0.5097 - val_loss: 1.5585 - val_accuracy: 0.4851\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 1.4396 - accuracy: 0.5085 - val_loss: 1.5439 - val_accuracy: 0.4751\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.4571 - accuracy: 0.4871 - val_loss: 1.5297 - val_accuracy: 0.5249\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.4370 - accuracy: 0.5144 - val_loss: 1.4924 - val_accuracy: 0.5050\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.4237 - accuracy: 0.5087 - val_loss: 1.5056 - val_accuracy: 0.5179\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.4144 - accuracy: 0.5147 - val_loss: 1.4747 - val_accuracy: 0.5229\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 1.3699 - accuracy: 0.5237 - val_loss: 1.5012 - val_accuracy: 0.5209\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 1.3833 - accuracy: 0.5142 - val_loss: 1.6246 - val_accuracy: 0.4631\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.5123 - accuracy: 0.4816 - val_loss: 1.4926 - val_accuracy: 0.5239\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.4230 - accuracy: 0.5326 - val_loss: 1.4797 - val_accuracy: 0.5299\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 1.3665 - accuracy: 0.5249 - val_loss: 1.4867 - val_accuracy: 0.5289\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 1.3493 - accuracy: 0.5374 - val_loss: 1.5203 - val_accuracy: 0.5139\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.3747 - accuracy: 0.5162 - val_loss: 1.5292 - val_accuracy: 0.4970\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 1.4037 - accuracy: 0.5319 - val_loss: 1.5113 - val_accuracy: 0.4930\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.3825 - accuracy: 0.5294 - val_loss: 1.4798 - val_accuracy: 0.5169\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.3949 - accuracy: 0.5296 - val_loss: 1.4893 - val_accuracy: 0.5020\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.3615 - accuracy: 0.5468 - val_loss: 1.5010 - val_accuracy: 0.5229\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.3681 - accuracy: 0.5366 - val_loss: 1.5400 - val_accuracy: 0.5030\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.4248 - accuracy: 0.5199 - val_loss: 1.4607 - val_accuracy: 0.5129\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.4125 - accuracy: 0.5453 - val_loss: 1.4689 - val_accuracy: 0.5169\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.3536 - accuracy: 0.5520 - val_loss: 1.4562 - val_accuracy: 0.5199\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 1.3530 - accuracy: 0.5411 - val_loss: 1.5062 - val_accuracy: 0.5189\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.3498 - accuracy: 0.5491 - val_loss: 1.5308 - val_accuracy: 0.5139\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.3554 - accuracy: 0.5304 - val_loss: 1.4798 - val_accuracy: 0.4920\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.4017 - accuracy: 0.5291 - val_loss: 1.5117 - val_accuracy: 0.5309\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.3736 - accuracy: 0.5478 - val_loss: 1.4509 - val_accuracy: 0.5329\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.3173 - accuracy: 0.5565 - val_loss: 1.4852 - val_accuracy: 0.5359\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.3108 - accuracy: 0.5468 - val_loss: 1.4560 - val_accuracy: 0.5120\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 1.3640 - accuracy: 0.5500 - val_loss: 1.4513 - val_accuracy: 0.5040\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.3365 - accuracy: 0.5473 - val_loss: 1.4378 - val_accuracy: 0.5438\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.2929 - accuracy: 0.5515 - val_loss: 1.5065 - val_accuracy: 0.5319\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 1.3004 - accuracy: 0.5535 - val_loss: 1.4621 - val_accuracy: 0.5229\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 1.3086 - accuracy: 0.5575 - val_loss: 1.4680 - val_accuracy: 0.5359\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.2996 - accuracy: 0.5583 - val_loss: 1.4876 - val_accuracy: 0.5100\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.3786 - accuracy: 0.5595 - val_loss: 1.4572 - val_accuracy: 0.5090\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.3483 - accuracy: 0.5451 - val_loss: 1.4428 - val_accuracy: 0.5448\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.3137 - accuracy: 0.5799 - val_loss: 1.4660 - val_accuracy: 0.5299\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.3001 - accuracy: 0.5747 - val_loss: 1.4173 - val_accuracy: 0.5508\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.3132 - accuracy: 0.5794 - val_loss: 1.4768 - val_accuracy: 0.5199\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 1.3016 - accuracy: 0.5623 - val_loss: 1.3859 - val_accuracy: 0.5508\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.2713 - accuracy: 0.5715 - val_loss: 1.5035 - val_accuracy: 0.5319\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.3171 - accuracy: 0.5632 - val_loss: 1.4772 - val_accuracy: 0.5398\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 1.3132 - accuracy: 0.5672 - val_loss: 1.4508 - val_accuracy: 0.5269\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 1.2831 - accuracy: 0.5759 - val_loss: 1.4334 - val_accuracy: 0.5299\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.2883 - accuracy: 0.5929 - val_loss: 1.4706 - val_accuracy: 0.5498\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.2670 - accuracy: 0.5914 - val_loss: 1.4581 - val_accuracy: 0.5199\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 1.3247 - accuracy: 0.5727 - val_loss: 1.4483 - val_accuracy: 0.5199\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 1.3088 - accuracy: 0.5675 - val_loss: 1.4260 - val_accuracy: 0.5538\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.2615 - accuracy: 0.5946 - val_loss: 1.4670 - val_accuracy: 0.5269\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.2680 - accuracy: 0.5837 - val_loss: 1.4530 - val_accuracy: 0.5538\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 1.2412 - accuracy: 0.5847 - val_loss: 1.4485 - val_accuracy: 0.5359\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 1.2447 - accuracy: 0.5862 - val_loss: 1.4634 - val_accuracy: 0.5558\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 1.2245 - accuracy: 0.5847 - val_loss: 1.4494 - val_accuracy: 0.5199\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.2720 - accuracy: 0.5670 - val_loss: 1.4301 - val_accuracy: 0.5588\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.2352 - accuracy: 0.5837 - val_loss: 1.4752 - val_accuracy: 0.5299\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.2396 - accuracy: 0.5874 - val_loss: 1.4578 - val_accuracy: 0.5488\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 1.3019 - accuracy: 0.5797 - val_loss: 1.4387 - val_accuracy: 0.5518\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.2628 - accuracy: 0.6003 - val_loss: 1.3765 - val_accuracy: 0.5398\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 1.2092 - accuracy: 0.6066 - val_loss: 1.4403 - val_accuracy: 0.5647\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.1835 - accuracy: 0.6103 - val_loss: 1.4983 - val_accuracy: 0.5349\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.2364 - accuracy: 0.5862 - val_loss: 1.4375 - val_accuracy: 0.5707\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.2553 - accuracy: 0.6051 - val_loss: 1.4074 - val_accuracy: 0.5548\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 1.2390 - accuracy: 0.5999 - val_loss: 1.3917 - val_accuracy: 0.5608\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.2120 - accuracy: 0.6058 - val_loss: 1.4661 - val_accuracy: 0.5518\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.2040 - accuracy: 0.6038 - val_loss: 1.4087 - val_accuracy: 0.5657\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.2448 - accuracy: 0.6076 - val_loss: 1.3901 - val_accuracy: 0.5647\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.2119 - accuracy: 0.6160 - val_loss: 1.3841 - val_accuracy: 0.5677\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.1622 - accuracy: 0.6297 - val_loss: 1.4183 - val_accuracy: 0.5627\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 1.1382 - accuracy: 0.6262 - val_loss: 1.4809 - val_accuracy: 0.5518\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.1707 - accuracy: 0.6133 - val_loss: 1.4689 - val_accuracy: 0.5498\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.2371 - accuracy: 0.5974 - val_loss: 1.3878 - val_accuracy: 0.5229\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 1.2184 - accuracy: 0.6185 - val_loss: 1.3945 - val_accuracy: 0.5817\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.1910 - accuracy: 0.6150 - val_loss: 1.4050 - val_accuracy: 0.5498\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 1.1604 - accuracy: 0.6225 - val_loss: 1.4261 - val_accuracy: 0.5697\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 1.1576 - accuracy: 0.6267 - val_loss: 1.3795 - val_accuracy: 0.5568\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 1.2366 - accuracy: 0.6111 - val_loss: 1.4028 - val_accuracy: 0.5418\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 1.2095 - accuracy: 0.6140 - val_loss: 1.3218 - val_accuracy: 0.5797\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.1445 - accuracy: 0.6280 - val_loss: 1.4086 - val_accuracy: 0.5508\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.1108 - accuracy: 0.6477 - val_loss: 1.3629 - val_accuracy: 0.5817\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.1434 - accuracy: 0.6123 - val_loss: 1.4830 - val_accuracy: 0.5139\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.2291 - accuracy: 0.6016 - val_loss: 1.3683 - val_accuracy: 0.5767\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 1.1720 - accuracy: 0.6285 - val_loss: 1.3231 - val_accuracy: 0.5747\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.1287 - accuracy: 0.6332 - val_loss: 1.3755 - val_accuracy: 0.5896\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.1067 - accuracy: 0.6472 - val_loss: 1.3531 - val_accuracy: 0.5837\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.0878 - accuracy: 0.6384 - val_loss: 1.4105 - val_accuracy: 0.5707\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.1166 - accuracy: 0.6345 - val_loss: 1.4129 - val_accuracy: 0.5568\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.1307 - accuracy: 0.6188 - val_loss: 1.4088 - val_accuracy: 0.5538\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.1369 - accuracy: 0.6292 - val_loss: 1.4200 - val_accuracy: 0.5847\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 1.1700 - accuracy: 0.6449 - val_loss: 1.4170 - val_accuracy: 0.5687\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.1056 - accuracy: 0.6447 - val_loss: 1.3772 - val_accuracy: 0.5807\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 1.1121 - accuracy: 0.6544 - val_loss: 1.3904 - val_accuracy: 0.5896\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.1065 - accuracy: 0.6564 - val_loss: 1.3834 - val_accuracy: 0.5657\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.1040 - accuracy: 0.6509 - val_loss: 1.3580 - val_accuracy: 0.5966\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 1.0651 - accuracy: 0.6457 - val_loss: 1.3464 - val_accuracy: 0.5637\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.0877 - accuracy: 0.6370 - val_loss: 1.3957 - val_accuracy: 0.5687\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 1.0936 - accuracy: 0.6449 - val_loss: 1.3441 - val_accuracy: 0.5637\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 1.0832 - accuracy: 0.6462 - val_loss: 1.3888 - val_accuracy: 0.5647\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.0937 - accuracy: 0.6663 - val_loss: 1.3126 - val_accuracy: 0.5906\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.1049 - accuracy: 0.6444 - val_loss: 1.3524 - val_accuracy: 0.5657\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.0860 - accuracy: 0.6604 - val_loss: 1.3042 - val_accuracy: 0.5896\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 1.0975 - accuracy: 0.6382 - val_loss: 1.4338 - val_accuracy: 0.5637\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.0674 - accuracy: 0.6579 - val_loss: 1.2920 - val_accuracy: 0.5876\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.0484 - accuracy: 0.6472 - val_loss: 1.4348 - val_accuracy: 0.5508\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.1032 - accuracy: 0.6514 - val_loss: 1.3717 - val_accuracy: 0.6026\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 1.1013 - accuracy: 0.6484 - val_loss: 1.3457 - val_accuracy: 0.5886\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.0647 - accuracy: 0.6559 - val_loss: 1.3379 - val_accuracy: 0.5906\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 1.0025 - accuracy: 0.6594 - val_loss: 1.3248 - val_accuracy: 0.6225\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.9956 - accuracy: 0.6736 - val_loss: 1.3732 - val_accuracy: 0.5767\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.0432 - accuracy: 0.6638 - val_loss: 1.2867 - val_accuracy: 0.5876\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 1.0448 - accuracy: 0.6596 - val_loss: 1.3284 - val_accuracy: 0.6145\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 1.0121 - accuracy: 0.6721 - val_loss: 1.3318 - val_accuracy: 0.6046\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.0170 - accuracy: 0.6678 - val_loss: 1.3116 - val_accuracy: 0.5996\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 1.0101 - accuracy: 0.6748 - val_loss: 1.3416 - val_accuracy: 0.5956\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.0355 - accuracy: 0.6526 - val_loss: 1.2769 - val_accuracy: 0.5966\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.0293 - accuracy: 0.6815 - val_loss: 1.3116 - val_accuracy: 0.5777\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.9886 - accuracy: 0.6738 - val_loss: 1.3241 - val_accuracy: 0.6255\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.9849 - accuracy: 0.6658 - val_loss: 1.2650 - val_accuracy: 0.5976\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.9764 - accuracy: 0.6855 - val_loss: 1.3352 - val_accuracy: 0.6235\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.9300 - accuracy: 0.6855 - val_loss: 1.2806 - val_accuracy: 0.6056\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.9362 - accuracy: 0.6892 - val_loss: 1.4081 - val_accuracy: 0.5986\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.0105 - accuracy: 0.6452 - val_loss: 1.2855 - val_accuracy: 0.5956\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.9992 - accuracy: 0.6698 - val_loss: 1.3331 - val_accuracy: 0.6135\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.9775 - accuracy: 0.6865 - val_loss: 1.2684 - val_accuracy: 0.6026\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.9837 - accuracy: 0.6833 - val_loss: 1.2694 - val_accuracy: 0.6125\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.9118 - accuracy: 0.7044 - val_loss: 1.3255 - val_accuracy: 0.6026\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.8961 - accuracy: 0.6858 - val_loss: 1.3054 - val_accuracy: 0.6026\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.9283 - accuracy: 0.6873 - val_loss: 1.3781 - val_accuracy: 0.5876\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.9661 - accuracy: 0.6723 - val_loss: 1.3133 - val_accuracy: 0.6016\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.9462 - accuracy: 0.6880 - val_loss: 1.2123 - val_accuracy: 0.6135\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.9263 - accuracy: 0.6927 - val_loss: 1.2993 - val_accuracy: 0.5976\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.9111 - accuracy: 0.7017 - val_loss: 1.2992 - val_accuracy: 0.6345\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.9097 - accuracy: 0.7029 - val_loss: 1.2860 - val_accuracy: 0.5956\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.9174 - accuracy: 0.7114 - val_loss: 1.2329 - val_accuracy: 0.6265\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.9223 - accuracy: 0.6975 - val_loss: 1.3136 - val_accuracy: 0.6096\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.9285 - accuracy: 0.6907 - val_loss: 1.2538 - val_accuracy: 0.6135\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.9004 - accuracy: 0.7099 - val_loss: 1.2098 - val_accuracy: 0.6255\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.8423 - accuracy: 0.7306 - val_loss: 1.3618 - val_accuracy: 0.5936\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.8531 - accuracy: 0.7094 - val_loss: 1.3527 - val_accuracy: 0.6195\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.9440 - accuracy: 0.6676 - val_loss: 1.2451 - val_accuracy: 0.6076\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.9334 - accuracy: 0.7042 - val_loss: 1.3224 - val_accuracy: 0.6215\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.8999 - accuracy: 0.6975 - val_loss: 1.2062 - val_accuracy: 0.6295\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.8529 - accuracy: 0.7087 - val_loss: 1.2484 - val_accuracy: 0.6305\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.8199 - accuracy: 0.7278 - val_loss: 1.2182 - val_accuracy: 0.6295\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.8000 - accuracy: 0.7388 - val_loss: 1.3238 - val_accuracy: 0.6255\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.8432 - accuracy: 0.7151 - val_loss: 1.2829 - val_accuracy: 0.6125\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.8562 - accuracy: 0.7166 - val_loss: 1.1547 - val_accuracy: 0.6355\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.7945 - accuracy: 0.7328 - val_loss: 1.2911 - val_accuracy: 0.6066\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.7922 - accuracy: 0.7453 - val_loss: 1.3076 - val_accuracy: 0.6295\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.8746 - accuracy: 0.7102 - val_loss: 1.3122 - val_accuracy: 0.5926\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.9076 - accuracy: 0.7054 - val_loss: 1.2988 - val_accuracy: 0.6514\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.8471 - accuracy: 0.7141 - val_loss: 1.2378 - val_accuracy: 0.6394\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.7668 - accuracy: 0.7590 - val_loss: 1.2235 - val_accuracy: 0.6444\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.7517 - accuracy: 0.7433 - val_loss: 1.2811 - val_accuracy: 0.6275\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.7654 - accuracy: 0.7445 - val_loss: 1.1929 - val_accuracy: 0.6414\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.7408 - accuracy: 0.7634 - val_loss: 1.2629 - val_accuracy: 0.6305\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.6991 - accuracy: 0.7689 - val_loss: 1.2312 - val_accuracy: 0.6365\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7181 - accuracy: 0.7672 - val_loss: 1.2806 - val_accuracy: 0.6116\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.7812 - accuracy: 0.7336 - val_loss: 1.3102 - val_accuracy: 0.6135\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.7936 - accuracy: 0.7281 - val_loss: 1.1921 - val_accuracy: 0.6245\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.7545 - accuracy: 0.7460 - val_loss: 1.2635 - val_accuracy: 0.6544\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.7770 - accuracy: 0.7433 - val_loss: 1.2992 - val_accuracy: 0.6165\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.7843 - accuracy: 0.7383 - val_loss: 1.1639 - val_accuracy: 0.6335\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.7342 - accuracy: 0.7507 - val_loss: 1.2613 - val_accuracy: 0.6225\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.7056 - accuracy: 0.7709 - val_loss: 1.2387 - val_accuracy: 0.6584\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.7255 - accuracy: 0.7562 - val_loss: 1.2457 - val_accuracy: 0.6245\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.7007 - accuracy: 0.7771 - val_loss: 1.1783 - val_accuracy: 0.6155\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.6993 - accuracy: 0.7649 - val_loss: 1.2227 - val_accuracy: 0.6683\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.6673 - accuracy: 0.7933 - val_loss: 1.2639 - val_accuracy: 0.6225\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.6463 - accuracy: 0.7869 - val_loss: 1.2197 - val_accuracy: 0.6624\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.6729 - accuracy: 0.7861 - val_loss: 1.1969 - val_accuracy: 0.6345\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.6413 - accuracy: 0.7869 - val_loss: 1.2621 - val_accuracy: 0.6305\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.6361 - accuracy: 0.7956 - val_loss: 1.2370 - val_accuracy: 0.6643\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.6349 - accuracy: 0.7781 - val_loss: 1.2522 - val_accuracy: 0.6275\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.6644 - accuracy: 0.7816 - val_loss: 1.2617 - val_accuracy: 0.6494\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.6130 - accuracy: 0.8105 - val_loss: 1.2123 - val_accuracy: 0.6604\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.6034 - accuracy: 0.8155 - val_loss: 1.2853 - val_accuracy: 0.6235\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.7034 - accuracy: 0.7717 - val_loss: 1.3302 - val_accuracy: 0.6434\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.6977 - accuracy: 0.7739 - val_loss: 1.2566 - val_accuracy: 0.6484\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.6814 - accuracy: 0.7839 - val_loss: 1.2482 - val_accuracy: 0.6564\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.6214 - accuracy: 0.8018 - val_loss: 1.2052 - val_accuracy: 0.6494\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.5952 - accuracy: 0.8237 - val_loss: 1.2626 - val_accuracy: 0.6305\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.5754 - accuracy: 0.8038 - val_loss: 1.1633 - val_accuracy: 0.6544\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.5839 - accuracy: 0.7971 - val_loss: 1.2836 - val_accuracy: 0.6036\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.6061 - accuracy: 0.7951 - val_loss: 1.1902 - val_accuracy: 0.6534\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.6221 - accuracy: 0.7898 - val_loss: 1.2452 - val_accuracy: 0.6285\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.5653 - accuracy: 0.8145 - val_loss: 1.1868 - val_accuracy: 0.6574\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.5217 - accuracy: 0.8481 - val_loss: 1.3079 - val_accuracy: 0.6116\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.5155 - accuracy: 0.8401 - val_loss: 1.2430 - val_accuracy: 0.6683\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.5440 - accuracy: 0.8155 - val_loss: 1.3144 - val_accuracy: 0.6205\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.5292 - accuracy: 0.8416 - val_loss: 1.2154 - val_accuracy: 0.6414\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.4912 - accuracy: 0.8499 - val_loss: 1.3174 - val_accuracy: 0.6006\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.5030 - accuracy: 0.8424 - val_loss: 1.3161 - val_accuracy: 0.6524\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.5186 - accuracy: 0.8284 - val_loss: 1.2845 - val_accuracy: 0.5876\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.5154 - accuracy: 0.8212 - val_loss: 1.3756 - val_accuracy: 0.6554\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.5427 - accuracy: 0.8267 - val_loss: 1.2987 - val_accuracy: 0.6036\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.5494 - accuracy: 0.8185 - val_loss: 1.3273 - val_accuracy: 0.6653\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.5220 - accuracy: 0.8429 - val_loss: 1.3578 - val_accuracy: 0.6225\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.4877 - accuracy: 0.8466 - val_loss: 1.3875 - val_accuracy: 0.6414\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.5677 - accuracy: 0.8277 - val_loss: 1.2773 - val_accuracy: 0.6225\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.5493 - accuracy: 0.8277 - val_loss: 1.3449 - val_accuracy: 0.6305\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.4994 - accuracy: 0.8546 - val_loss: 1.2896 - val_accuracy: 0.6375\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.4882 - accuracy: 0.8411 - val_loss: 1.2762 - val_accuracy: 0.6424\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.4453 - accuracy: 0.8723 - val_loss: 1.3747 - val_accuracy: 0.6335\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.4017 - accuracy: 0.9024 - val_loss: 1.3578 - val_accuracy: 0.6394\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.3882 - accuracy: 0.9124 - val_loss: 1.3905 - val_accuracy: 0.6066\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.4242 - accuracy: 0.8777 - val_loss: 1.5387 - val_accuracy: 0.6155\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.5266 - accuracy: 0.8160 - val_loss: 1.2909 - val_accuracy: 0.6375\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.5372 - accuracy: 0.8312 - val_loss: 1.3747 - val_accuracy: 0.6135\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.5060 - accuracy: 0.8541 - val_loss: 1.2636 - val_accuracy: 0.6873\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.4859 - accuracy: 0.8548 - val_loss: 1.3287 - val_accuracy: 0.6195\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.4228 - accuracy: 0.8755 - val_loss: 1.3225 - val_accuracy: 0.6365\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.4000 - accuracy: 0.8977 - val_loss: 1.3651 - val_accuracy: 0.6355\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.3899 - accuracy: 0.8932 - val_loss: 1.3781 - val_accuracy: 0.6175\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.3779 - accuracy: 0.9099 - val_loss: 1.4073 - val_accuracy: 0.6384\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.3688 - accuracy: 0.9006 - val_loss: 1.4352 - val_accuracy: 0.6026\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.3910 - accuracy: 0.8922 - val_loss: 1.4071 - val_accuracy: 0.6375\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.3808 - accuracy: 0.8979 - val_loss: 1.4250 - val_accuracy: 0.6165\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.3734 - accuracy: 0.9109 - val_loss: 1.4468 - val_accuracy: 0.6205\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.3775 - accuracy: 0.9106 - val_loss: 1.4165 - val_accuracy: 0.6195\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.3782 - accuracy: 0.8957 - val_loss: 1.5011 - val_accuracy: 0.5807\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.4351 - accuracy: 0.8645 - val_loss: 1.4191 - val_accuracy: 0.6185\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.4850 - accuracy: 0.8411 - val_loss: 1.4172 - val_accuracy: 0.6285\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.4081 - accuracy: 0.8904 - val_loss: 1.2561 - val_accuracy: 0.6843\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.3789 - accuracy: 0.9166 - val_loss: 1.4617 - val_accuracy: 0.6185\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.3408 - accuracy: 0.9355 - val_loss: 1.3375 - val_accuracy: 0.6504\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.3133 - accuracy: 0.9402 - val_loss: 1.4527 - val_accuracy: 0.6355\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.3161 - accuracy: 0.9377 - val_loss: 1.4049 - val_accuracy: 0.6285\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.3214 - accuracy: 0.9365 - val_loss: 1.5184 - val_accuracy: 0.6275\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.3374 - accuracy: 0.9151 - val_loss: 1.3749 - val_accuracy: 0.6155\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.3639 - accuracy: 0.9056 - val_loss: 1.5006 - val_accuracy: 0.6195\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.3236 - accuracy: 0.9345 - val_loss: 1.3484 - val_accuracy: 0.6255\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.3238 - accuracy: 0.9330 - val_loss: 1.3863 - val_accuracy: 0.6225\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.2993 - accuracy: 0.9415 - val_loss: 1.5255 - val_accuracy: 0.5986\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.3235 - accuracy: 0.9226 - val_loss: 1.4040 - val_accuracy: 0.6713\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.3031 - accuracy: 0.9377 - val_loss: 1.5890 - val_accuracy: 0.5926\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.3097 - accuracy: 0.9380 - val_loss: 1.4574 - val_accuracy: 0.7131\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.3860 - accuracy: 0.9158 - val_loss: 1.7496 - val_accuracy: 0.5627\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.9411 - accuracy: 0.6920 - val_loss: 1.4397 - val_accuracy: 0.7141\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.4908 - accuracy: 0.8745 - val_loss: 1.3013 - val_accuracy: 0.6574\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.4149 - accuracy: 0.8989 - val_loss: 1.3130 - val_accuracy: 0.7012\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.3270 - accuracy: 0.9380 - val_loss: 1.3405 - val_accuracy: 0.6843\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.2889 - accuracy: 0.9519 - val_loss: 1.3445 - val_accuracy: 0.7012\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.2678 - accuracy: 0.9626 - val_loss: 1.3952 - val_accuracy: 0.6892\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.2538 - accuracy: 0.9649 - val_loss: 1.3649 - val_accuracy: 0.6892\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.2470 - accuracy: 0.9699 - val_loss: 1.4836 - val_accuracy: 0.6813\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.2561 - accuracy: 0.9587 - val_loss: 1.3681 - val_accuracy: 0.6733\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.2594 - accuracy: 0.9582 - val_loss: 1.5010 - val_accuracy: 0.6773\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.2550 - accuracy: 0.9584 - val_loss: 1.3983 - val_accuracy: 0.6843\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.2368 - accuracy: 0.9724 - val_loss: 1.4285 - val_accuracy: 0.6773\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.2403 - accuracy: 0.9649 - val_loss: 1.5358 - val_accuracy: 0.6584\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.2532 - accuracy: 0.9537 - val_loss: 1.3365 - val_accuracy: 0.6823\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.2804 - accuracy: 0.9445 - val_loss: 1.5174 - val_accuracy: 0.6514\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.2738 - accuracy: 0.9377 - val_loss: 1.4114 - val_accuracy: 0.6813\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.2845 - accuracy: 0.9390 - val_loss: 1.4302 - val_accuracy: 0.6942\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.2471 - accuracy: 0.9589 - val_loss: 1.3737 - val_accuracy: 0.6833\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.2157 - accuracy: 0.9778 - val_loss: 1.4309 - val_accuracy: 0.6882\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.2125 - accuracy: 0.9729 - val_loss: 1.4702 - val_accuracy: 0.6733\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.2152 - accuracy: 0.9656 - val_loss: 1.4721 - val_accuracy: 0.6783\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.2249 - accuracy: 0.9624 - val_loss: 1.4750 - val_accuracy: 0.6584\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.2239 - accuracy: 0.9587 - val_loss: 1.4932 - val_accuracy: 0.6594\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.2013 - accuracy: 0.9699 - val_loss: 1.4610 - val_accuracy: 0.6574\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1921 - accuracy: 0.9793 - val_loss: 1.5666 - val_accuracy: 0.6624\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1920 - accuracy: 0.9719 - val_loss: 1.4759 - val_accuracy: 0.6245\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1922 - accuracy: 0.9749 - val_loss: 1.5920 - val_accuracy: 0.6753\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.2054 - accuracy: 0.9634 - val_loss: 1.5378 - val_accuracy: 0.6046\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.2717 - accuracy: 0.9350 - val_loss: 1.6288 - val_accuracy: 0.6464\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.3986 - accuracy: 0.9168 - val_loss: 1.4668 - val_accuracy: 0.6275\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.3373 - accuracy: 0.9168 - val_loss: 1.4045 - val_accuracy: 0.6683\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.3416 - accuracy: 0.9243 - val_loss: 1.3706 - val_accuracy: 0.6803\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.2684 - accuracy: 0.9612 - val_loss: 1.4122 - val_accuracy: 0.6873\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.2047 - accuracy: 0.9721 - val_loss: 1.3829 - val_accuracy: 0.6952\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1793 - accuracy: 0.9828 - val_loss: 1.4301 - val_accuracy: 0.6773\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1615 - accuracy: 0.9885 - val_loss: 1.4620 - val_accuracy: 0.6843\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1550 - accuracy: 0.9885 - val_loss: 1.4921 - val_accuracy: 0.6633\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.1628 - accuracy: 0.9831 - val_loss: 1.6109 - val_accuracy: 0.6424\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1941 - accuracy: 0.9691 - val_loss: 1.5195 - val_accuracy: 0.6663\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.2569 - accuracy: 0.9313 - val_loss: 1.7752 - val_accuracy: 0.6036\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.2199 - accuracy: 0.9579 - val_loss: 1.4437 - val_accuracy: 0.6793\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.2342 - accuracy: 0.9507 - val_loss: 1.5580 - val_accuracy: 0.6703\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.2090 - accuracy: 0.9664 - val_loss: 1.3760 - val_accuracy: 0.6763\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1868 - accuracy: 0.9714 - val_loss: 1.5093 - val_accuracy: 0.6673\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1481 - accuracy: 0.9920 - val_loss: 1.4256 - val_accuracy: 0.6753\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1472 - accuracy: 0.9871 - val_loss: 1.5900 - val_accuracy: 0.6534\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.1474 - accuracy: 0.9885 - val_loss: 1.4323 - val_accuracy: 0.6763\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1733 - accuracy: 0.9776 - val_loss: 1.6274 - val_accuracy: 0.6404\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.1449 - accuracy: 0.9888 - val_loss: 1.4595 - val_accuracy: 0.6803\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1385 - accuracy: 0.9890 - val_loss: 1.5539 - val_accuracy: 0.6663\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1201 - accuracy: 0.9895 - val_loss: 1.5959 - val_accuracy: 0.6733\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.1251 - accuracy: 0.9841 - val_loss: 1.5195 - val_accuracy: 0.6693\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.1400 - accuracy: 0.9796 - val_loss: 1.7030 - val_accuracy: 0.6604\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.2023 - accuracy: 0.9547 - val_loss: 1.5356 - val_accuracy: 0.6534\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.3128 - accuracy: 0.9275 - val_loss: 1.4690 - val_accuracy: 0.6643\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.3241 - accuracy: 0.9178 - val_loss: 1.4190 - val_accuracy: 0.6643\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.2449 - accuracy: 0.9465 - val_loss: 1.3776 - val_accuracy: 0.6882\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1920 - accuracy: 0.9679 - val_loss: 1.4611 - val_accuracy: 0.6823\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1430 - accuracy: 0.9846 - val_loss: 1.4524 - val_accuracy: 0.6922\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1217 - accuracy: 0.9910 - val_loss: 1.4984 - val_accuracy: 0.6803\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.1112 - accuracy: 0.9948 - val_loss: 1.5131 - val_accuracy: 0.6823\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.1049 - accuracy: 0.9948 - val_loss: 1.5553 - val_accuracy: 0.6673\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.1003 - accuracy: 0.9948 - val_loss: 1.5616 - val_accuracy: 0.6773\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1001 - accuracy: 0.9940 - val_loss: 1.6138 - val_accuracy: 0.6564\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0972 - accuracy: 0.9938 - val_loss: 1.5818 - val_accuracy: 0.6763\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0976 - accuracy: 0.9920 - val_loss: 1.6660 - val_accuracy: 0.6584\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1043 - accuracy: 0.9920 - val_loss: 1.5829 - val_accuracy: 0.6614\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.1289 - accuracy: 0.9768 - val_loss: 1.7313 - val_accuracy: 0.6524\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1355 - accuracy: 0.9821 - val_loss: 1.4892 - val_accuracy: 0.7022\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.1772 - accuracy: 0.9644 - val_loss: 1.9370 - val_accuracy: 0.5618\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.2531 - accuracy: 0.9178 - val_loss: 1.7259 - val_accuracy: 0.6803\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.5346 - accuracy: 0.8484 - val_loss: 1.7827 - val_accuracy: 0.5598\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.6217 - accuracy: 0.8040 - val_loss: 1.4309 - val_accuracy: 0.6982\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.2652 - accuracy: 0.9460 - val_loss: 1.3475 - val_accuracy: 0.7022\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1755 - accuracy: 0.9816 - val_loss: 1.3524 - val_accuracy: 0.7052\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.1460 - accuracy: 0.9861 - val_loss: 1.3884 - val_accuracy: 0.7082\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.1293 - accuracy: 0.9905 - val_loss: 1.4144 - val_accuracy: 0.7062\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1173 - accuracy: 0.9930 - val_loss: 1.4421 - val_accuracy: 0.7012\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1083 - accuracy: 0.9948 - val_loss: 1.4612 - val_accuracy: 0.7002\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1012 - accuracy: 0.9960 - val_loss: 1.4870 - val_accuracy: 0.6992\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0955 - accuracy: 0.9963 - val_loss: 1.4988 - val_accuracy: 0.6972\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0908 - accuracy: 0.9955 - val_loss: 1.5262 - val_accuracy: 0.6962\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0863 - accuracy: 0.9968 - val_loss: 1.5354 - val_accuracy: 0.6982\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0842 - accuracy: 0.9953 - val_loss: 1.5627 - val_accuracy: 0.6922\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0815 - accuracy: 0.9960 - val_loss: 1.5582 - val_accuracy: 0.6962\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.0783 - accuracy: 0.9960 - val_loss: 1.5874 - val_accuracy: 0.6932\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.0759 - accuracy: 0.9970 - val_loss: 1.6011 - val_accuracy: 0.6853\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0744 - accuracy: 0.9965 - val_loss: 1.5829 - val_accuracy: 0.6962\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0825 - accuracy: 0.9965 - val_loss: 1.7615 - val_accuracy: 0.6444\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1436 - accuracy: 0.9629 - val_loss: 1.4808 - val_accuracy: 0.6424\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.2663 - accuracy: 0.9059 - val_loss: 1.4703 - val_accuracy: 0.6902\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.1259 - accuracy: 0.9890 - val_loss: 1.4145 - val_accuracy: 0.6863\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0997 - accuracy: 0.9938 - val_loss: 1.5120 - val_accuracy: 0.6932\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.0800 - accuracy: 0.9963 - val_loss: 1.4756 - val_accuracy: 0.6932\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0732 - accuracy: 0.9965 - val_loss: 1.5575 - val_accuracy: 0.6892\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0701 - accuracy: 0.9958 - val_loss: 1.5491 - val_accuracy: 0.6823\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0647 - accuracy: 0.9970 - val_loss: 1.5934 - val_accuracy: 0.6912\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0659 - accuracy: 0.9950 - val_loss: 1.6075 - val_accuracy: 0.6843\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.0661 - accuracy: 0.9925 - val_loss: 1.6373 - val_accuracy: 0.6892\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.0597 - accuracy: 0.9968 - val_loss: 1.6484 - val_accuracy: 0.6813\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0597 - accuracy: 0.9963 - val_loss: 1.6902 - val_accuracy: 0.6783\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0598 - accuracy: 0.9955 - val_loss: 1.6581 - val_accuracy: 0.6733\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0599 - accuracy: 0.9958 - val_loss: 1.7298 - val_accuracy: 0.6703\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0687 - accuracy: 0.9918 - val_loss: 1.7736 - val_accuracy: 0.6922\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.1654 - accuracy: 0.9522 - val_loss: 1.5243 - val_accuracy: 0.6574\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.2990 - accuracy: 0.9405 - val_loss: 1.6831 - val_accuracy: 0.6624\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.2557 - accuracy: 0.9255 - val_loss: 1.4032 - val_accuracy: 0.6624\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.1816 - accuracy: 0.9622 - val_loss: 1.4197 - val_accuracy: 0.6733\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.1290 - accuracy: 0.9791 - val_loss: 1.3535 - val_accuracy: 0.6723\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.1075 - accuracy: 0.9861 - val_loss: 1.4767 - val_accuracy: 0.6942\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.1002 - accuracy: 0.9863 - val_loss: 1.4483 - val_accuracy: 0.6514\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0895 - accuracy: 0.9908 - val_loss: 1.4788 - val_accuracy: 0.6932\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0665 - accuracy: 0.9958 - val_loss: 1.4730 - val_accuracy: 0.6912\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.0575 - accuracy: 0.9973 - val_loss: 1.5184 - val_accuracy: 0.6873\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0534 - accuracy: 0.9978 - val_loss: 1.5538 - val_accuracy: 0.6783\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0517 - accuracy: 0.9973 - val_loss: 1.5771 - val_accuracy: 0.6793\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0494 - accuracy: 0.9970 - val_loss: 1.6135 - val_accuracy: 0.6723\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0497 - accuracy: 0.9970 - val_loss: 1.6381 - val_accuracy: 0.6713\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0463 - accuracy: 0.9980 - val_loss: 1.6509 - val_accuracy: 0.6743\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0430 - accuracy: 0.9985 - val_loss: 1.6832 - val_accuracy: 0.6663\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0412 - accuracy: 0.9988 - val_loss: 1.6932 - val_accuracy: 0.6683\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0397 - accuracy: 0.9988 - val_loss: 1.7311 - val_accuracy: 0.6633\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0388 - accuracy: 0.9993 - val_loss: 1.7179 - val_accuracy: 0.6753\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0388 - accuracy: 0.9990 - val_loss: 1.7976 - val_accuracy: 0.6653\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0417 - accuracy: 0.9990 - val_loss: 1.6963 - val_accuracy: 0.6882\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0543 - accuracy: 0.9940 - val_loss: 1.8987 - val_accuracy: 0.6355\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0915 - accuracy: 0.9783 - val_loss: 1.6854 - val_accuracy: 0.7042\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1634 - accuracy: 0.9539 - val_loss: 1.8470 - val_accuracy: 0.5906\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1643 - accuracy: 0.9435 - val_loss: 1.4930 - val_accuracy: 0.6972\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1118 - accuracy: 0.9739 - val_loss: 1.6007 - val_accuracy: 0.7141\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.0704 - accuracy: 0.9933 - val_loss: 1.5015 - val_accuracy: 0.7042\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0558 - accuracy: 0.9943 - val_loss: 1.5666 - val_accuracy: 0.6972\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.0466 - accuracy: 0.9965 - val_loss: 1.5705 - val_accuracy: 0.7052\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.0403 - accuracy: 0.9985 - val_loss: 1.6175 - val_accuracy: 0.6932\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.0394 - accuracy: 0.9965 - val_loss: 1.6239 - val_accuracy: 0.6952\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0420 - accuracy: 0.9958 - val_loss: 1.6800 - val_accuracy: 0.6892\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.0357 - accuracy: 0.9980 - val_loss: 1.6638 - val_accuracy: 0.6942\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0352 - accuracy: 0.9973 - val_loss: 1.7055 - val_accuracy: 0.6882\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.0330 - accuracy: 0.9975 - val_loss: 1.6949 - val_accuracy: 0.6952\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0310 - accuracy: 0.9980 - val_loss: 1.7448 - val_accuracy: 0.6882\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0298 - accuracy: 0.9990 - val_loss: 1.7194 - val_accuracy: 0.6863\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0298 - accuracy: 0.9993 - val_loss: 1.8042 - val_accuracy: 0.6892\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0323 - accuracy: 0.9993 - val_loss: 1.7130 - val_accuracy: 0.6833\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0511 - accuracy: 0.9955 - val_loss: 1.9774 - val_accuracy: 0.6524\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1860 - accuracy: 0.9363 - val_loss: 1.6573 - val_accuracy: 0.6454\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.3170 - accuracy: 0.8929 - val_loss: 1.6316 - val_accuracy: 0.6315\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.3519 - accuracy: 0.9148 - val_loss: 1.3398 - val_accuracy: 0.7062\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1016 - accuracy: 0.9883 - val_loss: 1.4587 - val_accuracy: 0.6962\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.0636 - accuracy: 0.9965 - val_loss: 1.4773 - val_accuracy: 0.7131\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0493 - accuracy: 0.9983 - val_loss: 1.5321 - val_accuracy: 0.7102\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0426 - accuracy: 0.9990 - val_loss: 1.5616 - val_accuracy: 0.7062\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0384 - accuracy: 0.9990 - val_loss: 1.6225 - val_accuracy: 0.6922\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0370 - accuracy: 0.9985 - val_loss: 1.6312 - val_accuracy: 0.6942\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0363 - accuracy: 0.9973 - val_loss: 1.6836 - val_accuracy: 0.6882\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0333 - accuracy: 0.9975 - val_loss: 1.6876 - val_accuracy: 0.6813\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0316 - accuracy: 0.9985 - val_loss: 1.7209 - val_accuracy: 0.6902\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0303 - accuracy: 0.9983 - val_loss: 1.7190 - val_accuracy: 0.6902\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0301 - accuracy: 0.9983 - val_loss: 1.8070 - val_accuracy: 0.6843\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0389 - accuracy: 0.9950 - val_loss: 1.7447 - val_accuracy: 0.6882\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0396 - accuracy: 0.9948 - val_loss: 1.7881 - val_accuracy: 0.6733\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0391 - accuracy: 0.9945 - val_loss: 1.7723 - val_accuracy: 0.6783\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0412 - accuracy: 0.9940 - val_loss: 1.7314 - val_accuracy: 0.6604\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0847 - accuracy: 0.9823 - val_loss: 1.8997 - val_accuracy: 0.6743\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.2706 - accuracy: 0.9178 - val_loss: 1.7508 - val_accuracy: 0.6275\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.1526 - accuracy: 0.9679 - val_loss: 1.5145 - val_accuracy: 0.7082\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1035 - accuracy: 0.9763 - val_loss: 1.4803 - val_accuracy: 0.7032\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0737 - accuracy: 0.9858 - val_loss: 1.4694 - val_accuracy: 0.6773\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0472 - accuracy: 0.9965 - val_loss: 1.5228 - val_accuracy: 0.6783\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0385 - accuracy: 0.9968 - val_loss: 1.5518 - val_accuracy: 0.6703\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0339 - accuracy: 0.9993 - val_loss: 1.5878 - val_accuracy: 0.6713\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0309 - accuracy: 0.9993 - val_loss: 1.6197 - val_accuracy: 0.6733\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0287 - accuracy: 0.9995 - val_loss: 1.6514 - val_accuracy: 0.6723\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0269 - accuracy: 0.9995 - val_loss: 1.6763 - val_accuracy: 0.6733\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0254 - accuracy: 0.9995 - val_loss: 1.7026 - val_accuracy: 0.6683\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0241 - accuracy: 0.9995 - val_loss: 1.7247 - val_accuracy: 0.6673\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0230 - accuracy: 0.9995 - val_loss: 1.7476 - val_accuracy: 0.6653\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0220 - accuracy: 0.9995 - val_loss: 1.7653 - val_accuracy: 0.6643\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0212 - accuracy: 0.9995 - val_loss: 1.7861 - val_accuracy: 0.6584\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0206 - accuracy: 0.9995 - val_loss: 1.7995 - val_accuracy: 0.6624\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0205 - accuracy: 0.9993 - val_loss: 1.8281 - val_accuracy: 0.6544\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0218 - accuracy: 0.9983 - val_loss: 1.8400 - val_accuracy: 0.6564\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0259 - accuracy: 0.9958 - val_loss: 1.8565 - val_accuracy: 0.6524\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.0283 - accuracy: 0.9950 - val_loss: 1.8742 - val_accuracy: 0.6604\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0320 - accuracy: 0.9948 - val_loss: 1.8844 - val_accuracy: 0.6643\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0269 - accuracy: 0.9973 - val_loss: 1.9152 - val_accuracy: 0.6584\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0354 - accuracy: 0.9945 - val_loss: 1.7916 - val_accuracy: 0.6803\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0303 - accuracy: 0.9940 - val_loss: 2.1857 - val_accuracy: 0.6484\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0397 - accuracy: 0.9933 - val_loss: 1.7487 - val_accuracy: 0.6902\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0550 - accuracy: 0.9871 - val_loss: 2.1586 - val_accuracy: 0.6574\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0931 - accuracy: 0.9808 - val_loss: 1.8246 - val_accuracy: 0.7251\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.2653 - accuracy: 0.9402 - val_loss: 1.4302 - val_accuracy: 0.6404\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.2292 - accuracy: 0.9447 - val_loss: 1.7381 - val_accuracy: 0.6773\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.1648 - accuracy: 0.9589 - val_loss: 1.4913 - val_accuracy: 0.6793\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1018 - accuracy: 0.9796 - val_loss: 1.5001 - val_accuracy: 0.7271\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0562 - accuracy: 0.9910 - val_loss: 1.5461 - val_accuracy: 0.7122\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0398 - accuracy: 0.9975 - val_loss: 1.5743 - val_accuracy: 0.7161\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0336 - accuracy: 0.9978 - val_loss: 1.6056 - val_accuracy: 0.7151\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0299 - accuracy: 0.9990 - val_loss: 1.6332 - val_accuracy: 0.7112\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0271 - accuracy: 0.9995 - val_loss: 1.6589 - val_accuracy: 0.7122\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0250 - accuracy: 0.9998 - val_loss: 1.6829 - val_accuracy: 0.7112\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0233 - accuracy: 0.9998 - val_loss: 1.7049 - val_accuracy: 0.7092\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0219 - accuracy: 0.9998 - val_loss: 1.7251 - val_accuracy: 0.7052\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0206 - accuracy: 0.9998 - val_loss: 1.7435 - val_accuracy: 0.7052\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.7604 - val_accuracy: 0.7032\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.7759 - val_accuracy: 0.7002\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.7903 - val_accuracy: 0.7002\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.8039 - val_accuracy: 0.6992\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.8169 - val_accuracy: 0.6992\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.8295 - val_accuracy: 0.6972\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.8417 - val_accuracy: 0.6972\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.8536 - val_accuracy: 0.6962\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.8652 - val_accuracy: 0.6942\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.8771 - val_accuracy: 0.6912\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.8860 - val_accuracy: 0.6892\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.9051 - val_accuracy: 0.6882\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.8889 - val_accuracy: 0.6863\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0363 - accuracy: 0.9925 - val_loss: 1.9741 - val_accuracy: 0.6902\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0603 - accuracy: 0.9831 - val_loss: 1.9853 - val_accuracy: 0.6853\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0676 - accuracy: 0.9841 - val_loss: 1.8040 - val_accuracy: 0.6882\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1400 - accuracy: 0.9661 - val_loss: 1.5925 - val_accuracy: 0.6624\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1839 - accuracy: 0.9544 - val_loss: 1.6855 - val_accuracy: 0.6853\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0973 - accuracy: 0.9731 - val_loss: 1.7220 - val_accuracy: 0.6703\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0974 - accuracy: 0.9744 - val_loss: 1.5071 - val_accuracy: 0.6882\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0792 - accuracy: 0.9875 - val_loss: 1.5125 - val_accuracy: 0.6873\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0350 - accuracy: 0.9983 - val_loss: 1.5295 - val_accuracy: 0.6942\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0235 - accuracy: 0.9995 - val_loss: 1.5604 - val_accuracy: 0.6813\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.0203 - accuracy: 0.9998 - val_loss: 1.5842 - val_accuracy: 0.6863\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0185 - accuracy: 0.9998 - val_loss: 1.6066 - val_accuracy: 0.6892\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0171 - accuracy: 0.9998 - val_loss: 1.6252 - val_accuracy: 0.6882\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0159 - accuracy: 0.9998 - val_loss: 1.6434 - val_accuracy: 0.6882\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0150 - accuracy: 0.9998 - val_loss: 1.6623 - val_accuracy: 0.6902\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0142 - accuracy: 0.9998 - val_loss: 1.6810 - val_accuracy: 0.6942\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0134 - accuracy: 0.9998 - val_loss: 1.6992 - val_accuracy: 0.6892\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0128 - accuracy: 0.9998 - val_loss: 1.7168 - val_accuracy: 0.6873\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0123 - accuracy: 0.9998 - val_loss: 1.7340 - val_accuracy: 0.6882\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0117 - accuracy: 0.9998 - val_loss: 1.7509 - val_accuracy: 0.6873\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.7675 - val_accuracy: 0.6892\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.7836 - val_accuracy: 0.6892\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.7994 - val_accuracy: 0.6873\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.8146 - val_accuracy: 0.6873\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.8293 - val_accuracy: 0.6843\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.8435 - val_accuracy: 0.6853\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.8573 - val_accuracy: 0.6863\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.8698 - val_accuracy: 0.6853\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.8883 - val_accuracy: 0.6833\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.8827 - val_accuracy: 0.6833\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.9256 - val_accuracy: 0.6843\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0094 - accuracy: 0.9993 - val_loss: 1.9065 - val_accuracy: 0.6833\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0202 - accuracy: 0.9960 - val_loss: 1.9090 - val_accuracy: 0.6753\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0243 - accuracy: 0.9950 - val_loss: 1.9345 - val_accuracy: 0.6803\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.0497 - accuracy: 0.9871 - val_loss: 2.1212 - val_accuracy: 0.6574\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.2008 - accuracy: 0.9350 - val_loss: 1.8896 - val_accuracy: 0.6733\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.2038 - accuracy: 0.9539 - val_loss: 1.6707 - val_accuracy: 0.6773\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.2716 - accuracy: 0.9031 - val_loss: 1.6483 - val_accuracy: 0.6484\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1509 - accuracy: 0.9634 - val_loss: 1.3987 - val_accuracy: 0.7052\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0635 - accuracy: 0.9895 - val_loss: 1.4740 - val_accuracy: 0.6932\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0378 - accuracy: 0.9960 - val_loss: 1.4871 - val_accuracy: 0.6892\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0297 - accuracy: 0.9985 - val_loss: 1.5128 - val_accuracy: 0.6892\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0253 - accuracy: 0.9988 - val_loss: 1.5343 - val_accuracy: 0.6833\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0223 - accuracy: 0.9998 - val_loss: 1.5561 - val_accuracy: 0.6843\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0200 - accuracy: 0.9998 - val_loss: 1.5775 - val_accuracy: 0.6863\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.5986 - val_accuracy: 0.6863\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.6186 - val_accuracy: 0.6823\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.6376 - val_accuracy: 0.6813\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.6564 - val_accuracy: 0.6813\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.6740 - val_accuracy: 0.6793\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.6927 - val_accuracy: 0.6783\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.7087 - val_accuracy: 0.6793\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.7280 - val_accuracy: 0.6763\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.7418 - val_accuracy: 0.6723\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.7603 - val_accuracy: 0.6713\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.7724 - val_accuracy: 0.6703\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.7908 - val_accuracy: 0.6713\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.8000 - val_accuracy: 0.6713\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.8212 - val_accuracy: 0.6713\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.8257 - val_accuracy: 0.6763\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.8494 - val_accuracy: 0.6723\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.8534 - val_accuracy: 0.6733\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.8707 - val_accuracy: 0.6713\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.8788 - val_accuracy: 0.6713\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.8954 - val_accuracy: 0.6713\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.9028 - val_accuracy: 0.6723\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.9202 - val_accuracy: 0.6713\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.9269 - val_accuracy: 0.6703\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.9441 - val_accuracy: 0.6693\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.9513 - val_accuracy: 0.6703\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.9673 - val_accuracy: 0.6683\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.9749 - val_accuracy: 0.6693\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.9902 - val_accuracy: 0.6673\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.9983 - val_accuracy: 0.6733\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.0125 - val_accuracy: 0.6673\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.0199 - val_accuracy: 0.6733\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.0356 - val_accuracy: 0.6673\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.0411 - val_accuracy: 0.6723\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.0611 - val_accuracy: 0.6663\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.0556 - val_accuracy: 0.6813\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.1090 - val_accuracy: 0.6663\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.0690 - val_accuracy: 0.6743\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0142 - accuracy: 0.9985 - val_loss: 2.7244 - val_accuracy: 0.5418\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7485 - accuracy: 0.8192 - val_loss: 2.2359 - val_accuracy: 0.6096\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.5459 - accuracy: 0.8643 - val_loss: 2.1332 - val_accuracy: 0.7032\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.1463 - accuracy: 0.9602 - val_loss: 1.9556 - val_accuracy: 0.6743\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0881 - accuracy: 0.9786 - val_loss: 1.7718 - val_accuracy: 0.6972\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0560 - accuracy: 0.9915 - val_loss: 1.7591 - val_accuracy: 0.6982\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0411 - accuracy: 0.9935 - val_loss: 1.7578 - val_accuracy: 0.6992\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0335 - accuracy: 0.9958 - val_loss: 1.7635 - val_accuracy: 0.7052\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0288 - accuracy: 0.9968 - val_loss: 1.7729 - val_accuracy: 0.7122\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0254 - accuracy: 0.9975 - val_loss: 1.7855 - val_accuracy: 0.7102\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0228 - accuracy: 0.9975 - val_loss: 1.7969 - val_accuracy: 0.7141\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0209 - accuracy: 0.9978 - val_loss: 1.8133 - val_accuracy: 0.7102\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.0192 - accuracy: 0.9983 - val_loss: 1.8200 - val_accuracy: 0.7112\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0182 - accuracy: 0.9980 - val_loss: 1.8490 - val_accuracy: 0.7082\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0168 - accuracy: 0.9985 - val_loss: 1.8428 - val_accuracy: 0.7102\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0159 - accuracy: 0.9990 - val_loss: 1.8633 - val_accuracy: 0.7042\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0143 - accuracy: 0.9988 - val_loss: 1.8789 - val_accuracy: 0.7092\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0135 - accuracy: 0.9988 - val_loss: 1.8808 - val_accuracy: 0.7062\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0122 - accuracy: 0.9995 - val_loss: 1.8977 - val_accuracy: 0.7072\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0114 - accuracy: 0.9995 - val_loss: 1.9022 - val_accuracy: 0.7062\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0107 - accuracy: 0.9995 - val_loss: 1.9156 - val_accuracy: 0.6962\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0102 - accuracy: 0.9998 - val_loss: 1.9208 - val_accuracy: 0.6942\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.0097 - accuracy: 0.9998 - val_loss: 1.9341 - val_accuracy: 0.6942\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0094 - accuracy: 0.9998 - val_loss: 1.9423 - val_accuracy: 0.6902\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0089 - accuracy: 0.9998 - val_loss: 1.9531 - val_accuracy: 0.6942\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.9639 - val_accuracy: 0.6873\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.9715 - val_accuracy: 0.6882\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.9844 - val_accuracy: 0.6863\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.9913 - val_accuracy: 0.6853\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.0045 - val_accuracy: 0.6843\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.0115 - val_accuracy: 0.6793\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.0246 - val_accuracy: 0.6793\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.0319 - val_accuracy: 0.6803\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.0441 - val_accuracy: 0.6783\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.0526 - val_accuracy: 0.6793\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.0619 - val_accuracy: 0.6763\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.0740 - val_accuracy: 0.6783\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.0792 - val_accuracy: 0.6733\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.0983 - val_accuracy: 0.6773\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.0965 - val_accuracy: 0.6713\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.1202 - val_accuracy: 0.6753\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.1174 - val_accuracy: 0.6713\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.1346 - val_accuracy: 0.6753\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.1389 - val_accuracy: 0.6723\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.1494 - val_accuracy: 0.6763\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.1540 - val_accuracy: 0.6753\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.1659 - val_accuracy: 0.6753\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.1665 - val_accuracy: 0.6763\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.1843 - val_accuracy: 0.6773\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.1828 - val_accuracy: 0.6753\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.2048 - val_accuracy: 0.6753\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.2063 - val_accuracy: 0.6753\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 2.1667 - val_accuracy: 0.6673\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0522 - accuracy: 0.9858 - val_loss: 2.2188 - val_accuracy: 0.6733\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0542 - accuracy: 0.9858 - val_loss: 2.2594 - val_accuracy: 0.6404\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0800 - accuracy: 0.9756 - val_loss: 2.2713 - val_accuracy: 0.6544\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1859 - accuracy: 0.9487 - val_loss: 1.8269 - val_accuracy: 0.6474\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1911 - accuracy: 0.9465 - val_loss: 1.5275 - val_accuracy: 0.6952\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0637 - accuracy: 0.9853 - val_loss: 1.5064 - val_accuracy: 0.6962\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0219 - accuracy: 0.9993 - val_loss: 1.5914 - val_accuracy: 0.6952\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.6346 - val_accuracy: 0.6972\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.6775 - val_accuracy: 0.6942\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.7180 - val_accuracy: 0.6922\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.7546 - val_accuracy: 0.6932\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.7872 - val_accuracy: 0.6912\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.8164 - val_accuracy: 0.6853\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.8428 - val_accuracy: 0.6823\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.8672 - val_accuracy: 0.6803\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.8900 - val_accuracy: 0.6763\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.9115 - val_accuracy: 0.6743\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.9318 - val_accuracy: 0.6733\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.9510 - val_accuracy: 0.6713\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.9692 - val_accuracy: 0.6663\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.9865 - val_accuracy: 0.6624\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.0030 - val_accuracy: 0.6604\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.0187 - val_accuracy: 0.6584\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.0337 - val_accuracy: 0.6574\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.0482 - val_accuracy: 0.6554\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.0623 - val_accuracy: 0.6564\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.0761 - val_accuracy: 0.6574\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.0897 - val_accuracy: 0.6564\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1030 - val_accuracy: 0.6574\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.1161 - val_accuracy: 0.6564\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1289 - val_accuracy: 0.6574\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1415 - val_accuracy: 0.6564\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1538 - val_accuracy: 0.6564\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1659 - val_accuracy: 0.6544\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1775 - val_accuracy: 0.6554\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.1886 - val_accuracy: 0.6564\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.1991 - val_accuracy: 0.6594\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.2091 - val_accuracy: 0.6614\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.2187 - val_accuracy: 0.6614\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.2277 - val_accuracy: 0.6614\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.2362 - val_accuracy: 0.6614\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.2443 - val_accuracy: 0.6624\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.2520 - val_accuracy: 0.6624\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.2591 - val_accuracy: 0.6624\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.2659 - val_accuracy: 0.6614\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.2724 - val_accuracy: 0.6633\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.2786 - val_accuracy: 0.6614\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.2855 - val_accuracy: 0.6614\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.2910 - val_accuracy: 0.6624\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.3025 - val_accuracy: 0.6604\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.3006 - val_accuracy: 0.6614\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.3274 - val_accuracy: 0.6604\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.2778 - val_accuracy: 0.6693\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 2.3168 - val_accuracy: 0.6643\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0475 - accuracy: 0.9895 - val_loss: 2.2866 - val_accuracy: 0.6584\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.1779 - accuracy: 0.9644 - val_loss: 1.8791 - val_accuracy: 0.6544\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1717 - accuracy: 0.9537 - val_loss: 1.6276 - val_accuracy: 0.6384\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1189 - accuracy: 0.9646 - val_loss: 1.4393 - val_accuracy: 0.6892\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0587 - accuracy: 0.9863 - val_loss: 1.4511 - val_accuracy: 0.7201\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0288 - accuracy: 0.9953 - val_loss: 1.5610 - val_accuracy: 0.7022\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0122 - accuracy: 0.9993 - val_loss: 1.5589 - val_accuracy: 0.7072\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0093 - accuracy: 0.9995 - val_loss: 1.5933 - val_accuracy: 0.7032\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0079 - accuracy: 0.9998 - val_loss: 1.6150 - val_accuracy: 0.6982\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0070 - accuracy: 0.9998 - val_loss: 1.6386 - val_accuracy: 0.7002\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0064 - accuracy: 0.9998 - val_loss: 1.6621 - val_accuracy: 0.7012\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0058 - accuracy: 0.9998 - val_loss: 1.6866 - val_accuracy: 0.7012\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 1.7105 - val_accuracy: 0.7032\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0050 - accuracy: 0.9998 - val_loss: 1.7337 - val_accuracy: 0.7042\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7557 - val_accuracy: 0.7032\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7768 - val_accuracy: 0.7012\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8044 - val_accuracy: 0.6992\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.8148 - val_accuracy: 0.6912\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 1.8478 - val_accuracy: 0.6902\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 1.8502 - val_accuracy: 0.6952\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8746 - val_accuracy: 0.6932\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.8910 - val_accuracy: 0.6942\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9066 - val_accuracy: 0.6882\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9213 - val_accuracy: 0.6882\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9354 - val_accuracy: 0.6882\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9491 - val_accuracy: 0.6873\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9623 - val_accuracy: 0.6863\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9756 - val_accuracy: 0.6843\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.9881 - val_accuracy: 0.6843\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0002 - val_accuracy: 0.6823\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0121 - val_accuracy: 0.6823\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0236 - val_accuracy: 0.6843\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0350 - val_accuracy: 0.6833\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0459 - val_accuracy: 0.6833\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0564 - val_accuracy: 0.6833\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0665 - val_accuracy: 0.6823\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.0767 - val_accuracy: 0.6823\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.0864 - val_accuracy: 0.6833\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.0960 - val_accuracy: 0.6833\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.1049 - val_accuracy: 0.6833\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.1140 - val_accuracy: 0.6823\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.1229 - val_accuracy: 0.6813\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.1318 - val_accuracy: 0.6813\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.1392 - val_accuracy: 0.6823\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.1482 - val_accuracy: 0.6823\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.1569 - val_accuracy: 0.6813\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1642 - val_accuracy: 0.6813\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1728 - val_accuracy: 0.6813\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1796 - val_accuracy: 0.6783\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.1880 - val_accuracy: 0.6783\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.1920 - val_accuracy: 0.6803\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.2002 - val_accuracy: 0.6823\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.2054 - val_accuracy: 0.6823\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.2118 - val_accuracy: 0.6823\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.2175 - val_accuracy: 0.6793\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.2238 - val_accuracy: 0.6803\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 9.9769e-04 - accuracy: 1.0000 - val_loss: 2.2293 - val_accuracy: 0.6813\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 9.7151e-04 - accuracy: 1.0000 - val_loss: 2.2351 - val_accuracy: 0.6843\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 9.4312e-04 - accuracy: 1.0000 - val_loss: 2.2442 - val_accuracy: 0.6833\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 9.1671e-04 - accuracy: 1.0000 - val_loss: 2.2491 - val_accuracy: 0.6843\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 8.8971e-04 - accuracy: 1.0000 - val_loss: 2.2606 - val_accuracy: 0.6823\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 8.6455e-04 - accuracy: 1.0000 - val_loss: 2.2665 - val_accuracy: 0.6803\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 8.3900e-04 - accuracy: 1.0000 - val_loss: 2.2724 - val_accuracy: 0.6843\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 8.1754e-04 - accuracy: 1.0000 - val_loss: 2.2803 - val_accuracy: 0.6793\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 7.9469e-04 - accuracy: 1.0000 - val_loss: 2.2912 - val_accuracy: 0.6853\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 7.7031e-04 - accuracy: 1.0000 - val_loss: 2.2894 - val_accuracy: 0.6783\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 7.5125e-04 - accuracy: 1.0000 - val_loss: 2.3381 - val_accuracy: 0.6823\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 7.5076e-04 - accuracy: 1.0000 - val_loss: 2.2775 - val_accuracy: 0.6763\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 8.7382e-04 - accuracy: 1.0000 - val_loss: 2.5835 - val_accuracy: 0.6713\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 2.3143 - val_accuracy: 0.6663\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.1473 - accuracy: 0.9634 - val_loss: 2.9130 - val_accuracy: 0.6106\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.6574 - accuracy: 0.8394 - val_loss: 2.2463 - val_accuracy: 0.6345\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1794 - accuracy: 0.9475 - val_loss: 2.3565 - val_accuracy: 0.6185\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0973 - accuracy: 0.9746 - val_loss: 2.0022 - val_accuracy: 0.6853\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0712 - accuracy: 0.9766 - val_loss: 1.9813 - val_accuracy: 0.6514\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0478 - accuracy: 0.9880 - val_loss: 1.9188 - val_accuracy: 0.6793\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0134 - accuracy: 0.9985 - val_loss: 1.9290 - val_accuracy: 0.6813\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0105 - accuracy: 0.9993 - val_loss: 1.9395 - val_accuracy: 0.6773\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.9475 - val_accuracy: 0.6793\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.9567 - val_accuracy: 0.6813\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.9659 - val_accuracy: 0.6813\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.9756 - val_accuracy: 0.6803\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.9862 - val_accuracy: 0.6823\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.9977 - val_accuracy: 0.6853\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.0099 - val_accuracy: 0.6843\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.0224 - val_accuracy: 0.6833\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.0351 - val_accuracy: 0.6843\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.0477 - val_accuracy: 0.6833\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.0602 - val_accuracy: 0.6823\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.0725 - val_accuracy: 0.6843\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.0846 - val_accuracy: 0.6833\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.0966 - val_accuracy: 0.6833\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1084 - val_accuracy: 0.6833\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1201 - val_accuracy: 0.6833\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1318 - val_accuracy: 0.6833\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1433 - val_accuracy: 0.6833\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.1547 - val_accuracy: 0.6833\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1661 - val_accuracy: 0.6843\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1774 - val_accuracy: 0.6833\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.1887 - val_accuracy: 0.6833\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.1998 - val_accuracy: 0.6803\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.2109 - val_accuracy: 0.6803\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.2219 - val_accuracy: 0.6793\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.2329 - val_accuracy: 0.6803\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.2438 - val_accuracy: 0.6783\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.2547 - val_accuracy: 0.6783\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.2656 - val_accuracy: 0.6753\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.2764 - val_accuracy: 0.6743\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.2872 - val_accuracy: 0.6743\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.2980 - val_accuracy: 0.6743\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.3089 - val_accuracy: 0.6723\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.3198 - val_accuracy: 0.6713\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.3307 - val_accuracy: 0.6703\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.3417 - val_accuracy: 0.6673\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.3528 - val_accuracy: 0.6673\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.3639 - val_accuracy: 0.6673\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.3751 - val_accuracy: 0.6703\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.3865 - val_accuracy: 0.6693\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.3980 - val_accuracy: 0.6673\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.4097 - val_accuracy: 0.6683\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.4219 - val_accuracy: 0.6663\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.4347 - val_accuracy: 0.6663\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.4483 - val_accuracy: 0.6663\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.4631 - val_accuracy: 0.6673\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.4789 - val_accuracy: 0.6653\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.4961 - val_accuracy: 0.6673\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 9.9476e-04 - accuracy: 1.0000 - val_loss: 2.5109 - val_accuracy: 0.6643\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 9.6754e-04 - accuracy: 1.0000 - val_loss: 2.5312 - val_accuracy: 0.6614\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 9.3953e-04 - accuracy: 1.0000 - val_loss: 2.5385 - val_accuracy: 0.6604\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 9.1278e-04 - accuracy: 1.0000 - val_loss: 2.5603 - val_accuracy: 0.6614\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 8.8635e-04 - accuracy: 1.0000 - val_loss: 2.5663 - val_accuracy: 0.6604\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 8.6034e-04 - accuracy: 1.0000 - val_loss: 2.5816 - val_accuracy: 0.6584\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 8.3562e-04 - accuracy: 1.0000 - val_loss: 2.5882 - val_accuracy: 0.6584\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 8.1181e-04 - accuracy: 1.0000 - val_loss: 2.5981 - val_accuracy: 0.6584\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 7.8887e-04 - accuracy: 1.0000 - val_loss: 2.6070 - val_accuracy: 0.6594\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 7.6663e-04 - accuracy: 1.0000 - val_loss: 2.6108 - val_accuracy: 0.6554\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 7.4598e-04 - accuracy: 1.0000 - val_loss: 2.6312 - val_accuracy: 0.6544\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 7.2524e-04 - accuracy: 1.0000 - val_loss: 2.6251 - val_accuracy: 0.6574\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 7.0445e-04 - accuracy: 1.0000 - val_loss: 2.6488 - val_accuracy: 0.6544\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 6.8463e-04 - accuracy: 1.0000 - val_loss: 2.6465 - val_accuracy: 0.6574\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 6.6524e-04 - accuracy: 1.0000 - val_loss: 2.6711 - val_accuracy: 0.6544\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 6.4655e-04 - accuracy: 1.0000 - val_loss: 2.6615 - val_accuracy: 0.6584\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 6.2925e-04 - accuracy: 1.0000 - val_loss: 2.6999 - val_accuracy: 0.6534\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 6.1253e-04 - accuracy: 1.0000 - val_loss: 2.6853 - val_accuracy: 0.6554\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 5.9460e-04 - accuracy: 1.0000 - val_loss: 2.7205 - val_accuracy: 0.6514\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 5.7657e-04 - accuracy: 1.0000 - val_loss: 2.7162 - val_accuracy: 0.6514\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 5.5981e-04 - accuracy: 1.0000 - val_loss: 2.7348 - val_accuracy: 0.6484\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 5.4363e-04 - accuracy: 1.0000 - val_loss: 2.7404 - val_accuracy: 0.6514\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 5.2810e-04 - accuracy: 1.0000 - val_loss: 2.7555 - val_accuracy: 0.6484\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 5.1305e-04 - accuracy: 1.0000 - val_loss: 2.7609 - val_accuracy: 0.6514\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 4.9845e-04 - accuracy: 1.0000 - val_loss: 2.7799 - val_accuracy: 0.6504\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 4.8434e-04 - accuracy: 1.0000 - val_loss: 2.7748 - val_accuracy: 0.6534\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 4.7111e-04 - accuracy: 1.0000 - val_loss: 2.8142 - val_accuracy: 0.6454\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 4.5932e-04 - accuracy: 1.0000 - val_loss: 2.7868 - val_accuracy: 0.6514\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 4.4791e-04 - accuracy: 1.0000 - val_loss: 2.8742 - val_accuracy: 0.6434\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 4.4255e-04 - accuracy: 1.0000 - val_loss: 2.8107 - val_accuracy: 0.6584\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 2.7217 - val_accuracy: 0.6614\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0542 - accuracy: 0.9875 - val_loss: 2.7633 - val_accuracy: 0.6315\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0963 - accuracy: 0.9793 - val_loss: 2.3025 - val_accuracy: 0.6763\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1821 - accuracy: 0.9617 - val_loss: 2.8158 - val_accuracy: 0.6056\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.1464 - accuracy: 0.9562 - val_loss: 1.6475 - val_accuracy: 0.7281\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0510 - accuracy: 0.9851 - val_loss: 1.7068 - val_accuracy: 0.6932\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0147 - accuracy: 0.9973 - val_loss: 1.7045 - val_accuracy: 0.6942\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 1.7526 - val_accuracy: 0.6942\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0071 - accuracy: 0.9990 - val_loss: 1.7793 - val_accuracy: 0.6932\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 1.7987 - val_accuracy: 0.6972\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 1.8116 - val_accuracy: 0.6922\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 1.8099 - val_accuracy: 0.6882\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8018 - val_accuracy: 0.6843\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8187 - val_accuracy: 0.6863\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8382 - val_accuracy: 0.6863\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.8602 - val_accuracy: 0.6843\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.8816 - val_accuracy: 0.6843\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9158 - val_accuracy: 0.6863\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.9526 - val_accuracy: 0.6853\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.9791 - val_accuracy: 0.6853\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0008 - val_accuracy: 0.6873\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0214 - val_accuracy: 0.6853\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.0434 - val_accuracy: 0.6853\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.0646 - val_accuracy: 0.6793\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0852 - val_accuracy: 0.6753\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.1058 - val_accuracy: 0.6743\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.1263 - val_accuracy: 0.6763\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.1463 - val_accuracy: 0.6753\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1669 - val_accuracy: 0.6733\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.1869 - val_accuracy: 0.6713\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.2069 - val_accuracy: 0.6693\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.2263 - val_accuracy: 0.6703\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.2457 - val_accuracy: 0.6693\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.2646 - val_accuracy: 0.6713\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.2834 - val_accuracy: 0.6693\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 9.6525e-04 - accuracy: 1.0000 - val_loss: 2.3017 - val_accuracy: 0.6703\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 9.2877e-04 - accuracy: 1.0000 - val_loss: 2.3198 - val_accuracy: 0.6723\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 8.9443e-04 - accuracy: 1.0000 - val_loss: 2.3373 - val_accuracy: 0.6713\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 8.6205e-04 - accuracy: 1.0000 - val_loss: 2.3546 - val_accuracy: 0.6683\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 8.3146e-04 - accuracy: 1.0000 - val_loss: 2.3714 - val_accuracy: 0.6673\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 8.0251e-04 - accuracy: 1.0000 - val_loss: 2.3878 - val_accuracy: 0.6663\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 7.7508e-04 - accuracy: 1.0000 - val_loss: 2.4042 - val_accuracy: 0.6663\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 7.4906e-04 - accuracy: 1.0000 - val_loss: 2.4197 - val_accuracy: 0.6673\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 7.2429e-04 - accuracy: 1.0000 - val_loss: 2.4359 - val_accuracy: 0.6653\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 7.0073e-04 - accuracy: 1.0000 - val_loss: 2.4506 - val_accuracy: 0.6643\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 6.7816e-04 - accuracy: 1.0000 - val_loss: 2.4667 - val_accuracy: 0.6643\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 6.5666e-04 - accuracy: 1.0000 - val_loss: 2.4809 - val_accuracy: 0.6624\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 6.3608e-04 - accuracy: 1.0000 - val_loss: 2.4967 - val_accuracy: 0.6643\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 6.1636e-04 - accuracy: 1.0000 - val_loss: 2.5107 - val_accuracy: 0.6624\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 5.9752e-04 - accuracy: 1.0000 - val_loss: 2.5262 - val_accuracy: 0.6614\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 5.7939e-04 - accuracy: 1.0000 - val_loss: 2.5400 - val_accuracy: 0.6614\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 5.6205e-04 - accuracy: 1.0000 - val_loss: 2.5551 - val_accuracy: 0.6614\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 5.4535e-04 - accuracy: 1.0000 - val_loss: 2.5688 - val_accuracy: 0.6614\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 5.2928e-04 - accuracy: 1.0000 - val_loss: 2.5836 - val_accuracy: 0.6594\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 5.1371e-04 - accuracy: 1.0000 - val_loss: 2.5971 - val_accuracy: 0.6574\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 4.9849e-04 - accuracy: 1.0000 - val_loss: 2.6116 - val_accuracy: 0.6574\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 4.8337e-04 - accuracy: 1.0000 - val_loss: 2.6250 - val_accuracy: 0.6574\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 4.6911e-04 - accuracy: 1.0000 - val_loss: 2.6393 - val_accuracy: 0.6574\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 4.5574e-04 - accuracy: 1.0000 - val_loss: 2.6526 - val_accuracy: 0.6584\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 4.4289e-04 - accuracy: 1.0000 - val_loss: 2.6662 - val_accuracy: 0.6594\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 4.3046e-04 - accuracy: 1.0000 - val_loss: 2.6791 - val_accuracy: 0.6584\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 4.1844e-04 - accuracy: 1.0000 - val_loss: 2.6922 - val_accuracy: 0.6594\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 4.0679e-04 - accuracy: 1.0000 - val_loss: 2.7048 - val_accuracy: 0.6574\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0db04e5190> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0db0556e50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZc0QC9pCfUS"
      },
      "source": [
        "## Run inference (sampling)\n",
        "\n",
        "1. encode input and retrieve initial decoder state\n",
        "2. run one step of decoder with this initial state\n",
        "and a \"start of sequence\" token as target.\n",
        "Output will be the next target token.\n",
        "3. Repeat with the current target token and current states\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1TriXq7nnD_q",
        "outputId": "d0f6dfbd-1125-4605-e655-fed1197f3f54"
      },
      "source": [
        "plt.savefig(\"plots.pdf\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeoEYHvnCfUS"
      },
      "source": [
        "# Define sampling models\n",
        "# Restore the model and construct the encoder and decoder.\n",
        "model = keras.models.load_model(\"s2s\")\n",
        "\n",
        "encoder_inputs = model.input[0]  # input_1\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_inputs = model.input[1]  # input_2\n",
        "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_lstm = model.layers[3]\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "decoder_dense = model.layers[4]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = keras.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index[\"[\"]] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"[\"\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence\n",
        "\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbPwmkrYCfUT"
      },
      "source": [
        "You can now generate decoded sentences as such:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "FU3pUrZXIGFc",
        "outputId": "497ef435-df15-4e95-ba00-0ffbb9524056"
      },
      "source": [
        "inwave[1]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99]'"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "eXFi9TBRILa6",
        "outputId": "4ebf6c12-2c36-4682-e4d2-80d8bf028099"
      },
      "source": [
        "tarwave[1]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[950,949,948,947,946,945,944,943,942,941,940,939,938,937,936,935,934,933,932,931,930,929,928,927,926,925,924,923,922,921,920,919,918,917,916,915,914,913,912,911,910,909,908,907,906,905,904,903,902,901]'"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcVG0RJ8CfUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e230756-f371-4e58-e8b7-147d70f753fd"
      },
      "source": [
        "for seq_index in range(2):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
        "    decoded_signal = decode_sequence(input_seq)\n",
        "    print(\"-\")\n",
        "    print(\"Input sentence:\", inwave[seq_index])\n",
        "    print(\"Decoded sentence:\", decoded_signal)\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input sentence: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49]\n",
            "Decoded sentence: [1000, 999, 998, 997, 996, 995, 994, 993, 992, 991, 990, 989, 988, 987, 986, 985, 984, 983, 982, 981, 980, 979, 978, 977, 976, 975, 974, 973, 972, 971, 970, 969, 968, 967, 966, 965, 964, 963, 962, 961, 960, 959, 958, 957, 956, 955, 954, 953, 952, 951] \n",
            "-\n",
            "Input sentence: [50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99]\n",
            "Decoded sentence: [950,949,948,947,946,945,944,943,942,941,940,939,938,937,936,935,934,933,932,931,930,929,928,927,926,925,924,923,922,921,920,919,918,917,916,915,914,913,912,911,910,909,908,907,906,905,904,903,902,901]                                                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWEfYXY5N5Kr"
      },
      "source": [
        "# Post processing after inference to convert back to array "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mW2rmNmMo0V"
      },
      "source": [
        "decoded_signal.strip( )\n",
        "decoded_signal = decoded_signal.replace('[','')\n",
        "decoded_signal = decoded_signal.replace(']','')\n",
        "output_signal = np.fromstring(decoded_signal, dtype=int, sep=',')"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUDWBoYJNof3",
        "outputId": "5fc0d94b-1b08-4319-c99e-3498a5292ddf"
      },
      "source": [
        "output_signal"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([950, 949, 948, 947, 946, 945, 944, 943, 942, 941, 940, 939, 938,\n",
              "       937, 936, 935, 934, 933, 932, 931, 930, 929, 928, 927, 926, 925,\n",
              "       924, 923, 922, 921, 920, 919, 918, 917, 916, 915, 914, 913, 912,\n",
              "       911, 910, 909, 908, 907, 906, 905, 904, 903, 902, 901])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySE8eP8ZMpWC"
      },
      "source": [
        ""
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUa8YDgeNyGJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}